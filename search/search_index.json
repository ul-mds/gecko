{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intro to Gecko","text":"<p>Gecko is a Python library for the bulk generation and mutation of realistic personal data. It aims to be the bigger brother of the GeCo framework which was originally published by Tran et al. in 2013<sup>1</sup>.</p> <p>Gecko brings a lot of quality-of-life and performance improvements over its predecessor. It is backed by Numpy and Pandas which allows for easy integration into existing data science applications, as well as massively improved performance by leveraging their vectorized functions wherever possible.</p> <p>The aim of Gecko is to provide a library which allows for the creation of shareable Python scripts that generate reliable and reproducible datasets.</p>"},{"location":"#installation","title":"Installation","text":"<p>To get started, install Gecko using your preferred package management tool.</p> <p>With pip:</p> <pre><code>pip install gecko-syndata\n</code></pre> <p>With Poetry:</p> <pre><code>poetry add gecko-syndata\n</code></pre>"},{"location":"#overview","title":"Overview","text":"<p>Writing a data generation script with Gecko is usually split into two consecutive steps. In the first step, data is generated based on information that you provide. Most commonly, Gecko pulls the information it needs from frequency tables, although other means of generating data are possible. Gecko will then output a dataset to your specifications.</p> <p>In the second step, a copy of this dataset is mutated. Gecko provides functions which deliberately introduce errors into your dataset. These errors can take shape in typos, edit errors and other common data sources. By the end, you will have a generated dataset and a mutated copy thereof.</p> <p></p> How to work with Gecko <p>Gecko is therefore composed of only two modules: <code>generator</code> and <code>mutator</code>. They are responsible for \u2014 as their names imply \u2014 generating and mutating data respectively. The <code>generator</code> module exposes generator functions which return data based on the information you provide them with. The <code>mutator</code> module exposes mutator functions which take in data columns and perform mutations on them.</p> <p></p> Gecko library overview <p>Gecko makes heavy use of Pandas' core data types: series and data frames. Basic familiarity with these data types helps with the adoption of Gecko, but is ultimately only useful if you intend to use Gecko in a data science application where Pandas is already in heavy use. In general, Gecko peruses series as columns containing data and data frames as tabular data containing one or more series.</p> <p>A generator is any function that takes in a number of values to create and returns a list of series, where each series contains the desired amount of generated values. Generators are expressed by the following type alias.</p>"},{"location":"#a-simple-example","title":"A simple example","text":"<p>If you haven't done so yet, install Gecko as described above. For this example, we will use the Gecko data repository as a source of information. To make use of it, simply obtain a copy of it by cloning it.</p> <pre><code>$ git clone https://github.com/ul-mds/gecko-data.git\n</code></pre> <p>Create a new script next to the directory where you cloned the Gecko data repository to. The following script generates a very simple dataset based on a frequency table of German given names and assigned genders. Once generated, the dataset is run through a couple generators that introduce random errors in the \"gender\" column and swapped digits in the \"age\" column. The generated and mutated dataset are then exported into CSV files.</p> <p>Tip: Click on the  icon in the code to get extra info on what a line of code does.</p> <pre><code>from pathlib import Path\n\nimport numpy as np\n\nfrom gecko import generator, mutator\n\nrng = np.random.default_rng(727)  # (1)!\ngecko_data_dir = Path(\"gecko-data\")  # (2)!\n\ndf_generated = generator.to_data_frame([  # (3)!\n    ((\"given_name\", \"gender\"), generator.from_multicolumn_frequency_table(  # (4)!\n        gecko_data_dir / \"de_DE\" / \"given-name-gender.csv\",\n        value_columns=[\"given_name\", \"gender\"],\n        freq_column=\"count\",\n        rng=rng,\n    )),\n    (\"age\", generator.from_uniform_distribution(  # (5)!\n        low=18, high=120, precision=0, rng=rng,\n    ))\n], 10_000)  # (6)!\n\ndf_mutated = mutator.mutate_data_frame(  # (7)!\n    df_generated,\n    [\n        (\"gender\", (.01, mutator.with_categorical_values(  # (8)!\n            gecko_data_dir / \"de_DE\" / \"given-name-gender.csv\",\n            value_column=\"gender\",\n            rng=rng,\n        ))),\n        (\"age\", (.02, mutator.with_transpose(rng))),  # (9)!\n    ],\n)\n\ndf_generated.to_csv(\"german-generated.csv\", index_label=\"id\")  # (10)!\ndf_mutated.to_csv(\"german-mutated.csv\", index_label=\"id\")\n</code></pre> <ol> <li>To get reproducible results, we need a random number generator (RNG) with a set seed. This guarantees that the output    is always the same regardless of how many times the script is run.</li> <li>This assumes that the Gecko data repository resides next to your script. If it doesn't, you need to adjust this path    accordingly.</li> <li><code>to_data_frame</code> is one of Gecko's main helper functions. It allows you to map column names to generators and puts out    a data frame according to your specifications.</li> <li>To generate given names and associated genders, we use the corresponding frequency table from the Gecko data    repository. The <code>from_multicolumn_frequency_table</code> generator needs to know where the frequency table is and what the    value columns and the frequency column are called. Almost all generators and mutators also accept a <code>rng</code> argument    which allows you to pass in your own RNG instance for predictable results.</li> <li>To generate ages, we draw random numbers from a uniform distribution. This distributions has a lower limit of 18 and    an upper limit of 120. To avoid floating point numbers, we set the precision to zero. Of course, in reality ages are    never uniformly distributed. This is just for demonstration purposes.</li> <li>We need to specify how many rows should be generated. 10,000 is a very conservative number for testing purposes. But    since Gecko is built with performance in mind, why not try to add some more zeros to that number?</li> <li><code>mutate_data_frame</code> is another one of Gecko's main helper functions. It allows you to apply mutators to specific    columns in a data frame.</li> <li>If you have a look into the frequency table for given names and assigned genders, you'll notice there is a limited    number of options for values that a person's gender can take on. This mutator looks at all possible values for the    \"gender\" column and only replaces values with another random permitted value. Note the <code>.01</code> at the beginning. This    denotes that 1% of all rows will be affected by this mutator.</li> <li>For the \"age\" column, we want 2% of all values to have some of their digits flipped. This mutator selects neighboring    characters at random and swaps them.</li> <li>Once we got both our datasets, we can export them using Pandas' <code>to_csv</code> function. Since Gecko's helper functions     return plain data frames, anything you can do with Pandas will also work with anything Gecko produces.</li> </ol>"},{"location":"#whats-next","title":"What's next?","text":"<p>This has been a brief overview of Gecko and its features. The remainder of this documentation provides a deep dive into the <code>generator</code> and <code>mutator</code> modules. For a more hands-on approach, check out some of the examples.</p> <ol> <li> <p>See: Tran, K. N., Vatsalan, D., &amp; Christen, P. (2013, October). GeCo: an online personal data generator and corruptor. In Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management (pp. 2473-2476).\u00a0\u21a9</p> </li> </ol>"},{"location":"api-reference/","title":"API reference","text":""},{"location":"api-reference/#generator","title":"Generator","text":"<p>The generator module provides generator functions for generating realistic data. These generators wrap around common data sources such as frequency tables and numeric distributions.</p>"},{"location":"api-reference/#gecko.generator.from_datetime_range","title":"<code>from_datetime_range(start_dt, end_dt, dt_format, unit, rng=None)</code>","text":"<p>Generate data from a range of dates and times. The start and end datetime must be provided either as a ISO 8601 datetime string or a NumPy datetime object. The output format must include the same format codes as specified in the <code>datetime</code> Python module for the <code>strftime</code> function. The unit specifies the smallest unit of time that may change when generating random dates and times. For example if <code>D</code> is specified, generated dates will only differ in their days, months and years, leaving hours, minutes and seconds unaffected. The same applies for <code>h</code>, <code>m</code> and <code>s</code> for hours, minutes and seconds respectively.</p> <p>Parameters:</p> Name Type Description Default <code>start_dt</code> <code>Union[str, datetime64]</code> <p>datetime string or object for start of range</p> required <code>end_dt</code> <code>Union[str, datetime64]</code> <p>datetime string or object for end of range</p> required <code>dt_format</code> <code>str</code> <p>output format for generated datetimes</p> required <code>unit</code> <code>DateTimeUnit</code> <p>smallest unit of time that may change when generating random dates and times</p> required <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>function returning list of random datetime strings within the specified range</p> Source code in <code>gecko/generator.py</code> <pre><code>def from_datetime_range(\n    start_dt: _t.Union[str, np.datetime64],\n    end_dt: _t.Union[str, np.datetime64],\n    dt_format: str,\n    unit: _gt.DateTimeUnit,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Generator:\n    \"\"\"\n    Generate data from a range of dates and times.\n    The start and end datetime must be provided either as a ISO 8601 datetime string or a NumPy datetime object.\n    The output format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    The unit specifies the smallest unit of time that may change when generating random dates and times.\n    For example if `D` is specified, generated dates will only differ in their days, months and years, leaving hours,\n    minutes and seconds unaffected.\n    The same applies for `h`, `m` and `s` for hours, minutes and seconds respectively.\n\n    Args:\n        start_dt: datetime string or object for start of range\n        end_dt: datetime string or object for end of range\n        dt_format: output format for generated datetimes\n        unit: smallest unit of time that may change when generating random dates and times\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random datetime strings within the specified range\n    \"\"\"\n    if isinstance(start_dt, str):\n        start_dt = np.datetime64(start_dt)\n\n    if isinstance(end_dt, str):\n        end_dt = np.datetime64(end_dt)\n\n    if start_dt &gt;= end_dt:\n        raise ValueError(f\"start datetime `{start_dt}` is greater than end datetime `{end_dt}`\")\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    pd_dt_unit = _gt.convert_gecko_date_time_unit_to_pandas(unit)\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        delta_td = end_dt - start_dt\n        delta_amt = int(delta_td / np.timedelta64(1, pd_dt_unit))\n        random_vals = rng.integers(low=0, high=delta_amt, size=count, endpoint=True)\n        random_dts = start_dt + random_vals.astype(f\"timedelta64[{pd_dt_unit}]\")\n        dt_srs = pd.Series(random_dts)\n\n        return [dt_srs.dt.strftime(dt_format)]\n\n    return _generate\n</code></pre>"},{"location":"api-reference/#gecko.generator.from_frequency_table","title":"<code>from_frequency_table(data_source, value_column=0, freq_column=1, encoding='utf-8', delimiter=',', rng=None)</code>","text":"<p>Generate data from a frequency table. The frequency table must be provided in CSV format and contain at least two columns: one containing values to generate and one containing their assigned absolute frequencies. Values generated by this function will have a distribution similar to the frequencies listed in the input file. If the value and frequency column are provided as strings, then it is automatically assumed that the CSV file has a header row.</p> <p>Parameters:</p> Name Type Description Default <code>data_source</code> <code>Union[str, PathLike[str], DataFrame]</code> <p>path to CSV file or data frame to use as frequency table</p> required <code>value_column</code> <code>Union[str, int]</code> <p>name or index of the value column</p> <code>0</code> <code>freq_column</code> <code>Union[str, int]</code> <p>name or index of the frequency column</p> <code>1</code> <code>encoding</code> <code>str</code> <p>character encoding of the CSV file</p> <code>'utf-8'</code> <code>delimiter</code> <code>str</code> <p>column delimiter of the CSV file</p> <code>','</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>function returning list with single series containing values generated from the input file</p> Source code in <code>gecko/generator.py</code> <pre><code>def from_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    freq_column: _t.Union[str, int] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table.\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the value and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_column: name or index of the value column\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with single series containing values generated from the input file\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    if type(value_column) is not type(freq_column):\n        raise ValueError(\"value and frequency columns must be of the same type\")\n\n    # skip check for value_column bc they are both of the same type already\n    if not isinstance(freq_column, (str, int)):\n        raise ValueError(\"value and frequency columns must be either a string or an integer\")\n\n    if isinstance(data_source, pd.DataFrame):\n        df = data_source\n    else:\n        header = isinstance(freq_column, str)\n\n        # read csv file\n        df = pd.read_csv(\n            data_source,\n            header=0 if header else None,  # header row index (`None` if not present)\n            usecols=[value_column, freq_column],\n            dtype={freq_column: \"int\", value_column: \"str\"},\n            keep_default_na=False,\n            sep=delimiter,\n            encoding=encoding,\n        )\n\n    # convert absolute to relative frequencies\n    srs_value = df[value_column]\n    srs_prob = df[freq_column] / df[freq_column].sum()\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        return [pd.Series(rng.choice(srs_value, count, p=srs_prob))]\n\n    return _generate\n</code></pre>"},{"location":"api-reference/#gecko.generator.from_function","title":"<code>from_function(func, *args, **kwargs)</code>","text":"<p>Generate data from an arbitrary function that returns a single value at a time.</p> Notes <p>This function should be used sparingly since it is not vectorized. Only use it for testing purposes or if performance is not important.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[_P, str]</code> <p>function to invoke to generate data from</p> required <code>*args</code> <code>object</code> <p>positional arguments to pass to <code>func</code></p> <code>()</code> <code>**kwargs</code> <code>object</code> <p>keyword arguments to pass to <code>func</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>Generator</code> <p>function returning list with strings generated from custom function</p> Source code in <code>gecko/generator.py</code> <pre><code>def from_function(func: _t.Callable[_P, str], *args: object, **kwargs: object) -&gt; _gt.Generator:\n    \"\"\"\n    Generate data from an arbitrary function that returns a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to invoke to generate data from\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function returning list with strings generated from custom function\n    \"\"\"\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        return [pd.Series(data=[func(*args, **kwargs) for _ in np.arange(count)])]\n\n    return _generate\n</code></pre>"},{"location":"api-reference/#gecko.generator.from_group","title":"<code>from_group(generator_lst, max_rounding_adjustment=0, rng=None)</code>","text":"<p>Generate data from multiple generators. Unless explicitly specified, all generators will generate data with equal probability. Alternatively generators can be assigned fixed probabilities. The output of each generator is then shuffled. If all generators generate multiple series, then all series are shuffled the same. Due to rounding errors, it may occur that the computed amount of rows to generate for each generator does not exactly sum up to the desired amount of rows. To compensate, this generator allows the specification of a maximum amount of rows that may be added or removed to random generators to match the target amount of rows.</p> <p>Parameters:</p> Name Type Description Default <code>generator_lst</code> <code>Union[list[Generator], list[_WeightedGenerator]]</code> <p>list of (weighted) generators</p> required <code>max_rounding_adjustment</code> <code>int</code> <p>maximum amount of rows to add or remove if the computed amount of total rows does not match the desired amount of rows</p> <code>0</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>function returning list of random data generated using supplied generators</p> Source code in <code>gecko/generator.py</code> <pre><code>def from_group(\n    generator_lst: _t.Union[list[_gt.Generator], list[_WeightedGenerator]],\n    max_rounding_adjustment: int = 0,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Generator:\n    \"\"\"\n    Generate data from multiple generators.\n    Unless explicitly specified, all generators will generate data with equal probability.\n    Alternatively generators can be assigned fixed probabilities.\n    The output of each generator is then shuffled.\n    If all generators generate multiple series, then all series are shuffled the same.\n    Due to rounding errors, it may occur that the computed amount of rows to generate for each generator does\n    not exactly sum up to the desired amount of rows.\n    To compensate, this generator allows the specification of a maximum amount of rows that may be added or removed\n    to random generators to match the target amount of rows.\n\n    Args:\n        generator_lst: list of (weighted) generators\n        max_rounding_adjustment: maximum amount of rows to add or remove if the computed amount of total rows does not match the desired amount of rows\n        rng: random number generator to use\n\n    Returns:\n        function returning list of random data generated using supplied generators\n    \"\"\"\n    if max_rounding_adjustment &lt; 0:\n        raise ValueError(f\"rounding adjustment must not be negative, is {max_rounding_adjustment}\")\n\n    if all(callable(g) for g in generator_lst):\n        p_per_generator = 1 / len(generator_lst)\n        generator_lst = [(p_per_generator, g) for g in generator_lst]\n\n    if not all(_is_weighted_generator(g) for g in generator_lst):\n        raise ValueError(\"invalid argument, must be a list of generators or weighted generators\")\n\n    p_vals = tuple(g[0] for g in generator_lst)\n    p_sum = sum(p_vals)\n\n    try:\n        rng.choice(np.arange(0, len(generator_lst)), p=p_vals)\n    except ValueError:\n        raise ValueError(f\"sum of weights must be 1, is {p_sum}\")\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        count_per_generator = list(round(count * p) for p in p_vals)  # get absolute counts for each generator\n        count_sum = sum(count_per_generator)\n\n        if count_sum != count:\n            if max_rounding_adjustment == 0:\n                raise ValueError(\n                    f\"sum of values per generator does not equal amount of desired rows: expected {count}, \"\n                    f\"is {count_sum} - this is likely due to rounding errors and can be compensated for \"\n                    \"by adjusting `max_rounding_adjustment`\"\n                )\n\n            count_diff = count - count_sum\n\n            if abs(count_diff) &gt; max_rounding_adjustment:\n                raise ValueError(\n                    f\"sum of values per generator does not equal amount of desired rows: expected {count}, \"\n                    f\"is {count_sum} - this is likely due to rounding errors, but `max_rounding_adjustment` \"\n                    \"is set so it cannot account for this difference\"\n                )\n\n            # draw random indices to adjust\n            adjustment = np.sign(count_diff)\n            idx_to_adjust = rng.choice(np.arange(0, len(count_per_generator)), size=abs(count_diff))\n\n            for idx in idx_to_adjust:\n                count_per_generator[idx] += adjustment\n\n        generated_series_lsts: list[list[pd.Series]] = []\n\n        for i, weighted_generator in enumerate(generator_lst):\n            _, gen = weighted_generator  # drop first argument since we won't be needing the p for this generator\n            generated_series_lsts.append(gen(count_per_generator[i]))\n\n        column_counts = set(len(srs_lst) for srs_lst in generated_series_lsts)\n\n        if len(column_counts) != 1:\n            raise ValueError(\n                f\"generators returned different amounts of columns: \"\n                f\"got {', '.join(str(c) for c in sorted(column_counts))}\"\n            )\n\n        column_count = column_counts.pop()  # get column count\n\n        srs_lst_out = [\n            pd.concat(\n                [srs_lst[i] for srs_lst in generated_series_lsts],\n                axis=0,\n                ignore_index=True,\n            )\n            for i in range(column_count)\n        ]\n\n        # reindex randomly\n        rand_idx = np.arange(0, count)\n        rng.shuffle(rand_idx)\n\n        return [srs.iloc[rand_idx].reset_index(drop=True) for srs in srs_lst_out]\n\n    return _generate\n</code></pre>"},{"location":"api-reference/#gecko.generator.from_multicolumn_frequency_table","title":"<code>from_multicolumn_frequency_table(data_source, value_columns=0, freq_column=1, encoding='utf-8', delimiter=',', rng=None)</code>","text":"<p>Generate data from a frequency table with multiple interdependent columns.. The frequency table must be provided in CSV format and contain at least two columns: one containing values to generate and one containing their assigned absolute frequencies. Values generated by this function will have a distribution similar to the frequencies listed in the input file. If the values and frequency column are provided as strings, then it is automatically assumed that the CSV file has a header row.</p> <p>Parameters:</p> Name Type Description Default <code>data_source</code> <code>Union[str, PathLike[str], DataFrame]</code> <p>path to CSV file or data frame to use as frequency table</p> required <code>value_columns</code> <code>Union[int, str, list[int], list[str]]</code> <p>names or indices of the value columns</p> <code>0</code> <code>freq_column</code> <code>Union[int, str]</code> <p>name or index of the frequency column</p> <code>1</code> <code>encoding</code> <code>str</code> <p>character encoding of the CSV file</p> <code>'utf-8'</code> <code>delimiter</code> <code>str</code> <p>column delimiter of the CSV file</p> <code>','</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>function returning list with as many series as there are value columns specified containing values generated from the input file</p> Source code in <code>gecko/generator.py</code> <pre><code>def from_multicolumn_frequency_table(\n    data_source: _t.Union[str, PathLike[str], pd.DataFrame],\n    value_columns: _t.Union[int, str, list[int], list[str]] = 0,\n    freq_column: _t.Union[int, str] = 1,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Generator:\n    \"\"\"\n    Generate data from a frequency table with multiple interdependent columns..\n    The frequency table must be provided in CSV format and contain at least two columns: one containing values to\n    generate and one containing their assigned absolute frequencies.\n    Values generated by this function will have a distribution similar to the frequencies listed in the input file.\n    If the values and frequency column are provided as strings, then it is automatically assumed that the CSV file\n    has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame to use as frequency table\n        value_columns: names or indices of the value columns\n        freq_column: name or index of the frequency column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function returning list with as many series as there are value columns specified containing values generated from the input file\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # coalesce into list\n    if not isinstance(value_columns, list):\n        value_columns = [value_columns]\n\n    # check that list is not empty\n    if len(value_columns) == 0:\n        raise ValueError(\"value column list cannot be empty\")\n\n    # peek at type of first value column\n    if type(value_columns[0]) is not type(freq_column):\n        raise ValueError(\"value and frequency columns must be of the same type\")\n\n    # skip check for value_columns bc they are both of the same type already\n    if not isinstance(freq_column, str) and not isinstance(freq_column, int):\n        raise ValueError(\"value and frequency column must be either a string or an integer\")\n\n    # now check that all other entries in the value column are of the same type as the first entry\n    # (which has been validated already)\n    for i in range(1, len(value_columns)):\n        if not isinstance(value_columns[i], type(value_columns[0])):\n            raise ValueError(\"value and frequency column must be either a string or an integer\")\n\n    if isinstance(data_source, pd.DataFrame):\n        df = data_source\n    else:\n        header = isinstance(freq_column, str)\n\n        df = pd.read_csv(\n            data_source,\n            header=0 if header else None,\n            usecols=value_columns + [freq_column],\n            dtype={\n                freq_column: \"int\",\n                **{value_column: \"str\" for value_column in value_columns},\n            },\n            keep_default_na=False,\n            sep=delimiter,\n            encoding=encoding,\n        )\n\n    # sum of absolute frequencies\n    freq_total = df[freq_column].sum()\n    # new series to track the relative frequencies\n    value_tuple_list = list(zip(*[list(df[c]) for c in value_columns]))\n    rel_freq_list = list(df[freq_column] / freq_total)\n\n    # noinspection PyTypeChecker\n    def _generate(count: int) -&gt; list[pd.Series]:\n        x = rng.choice(value_tuple_list, count, p=rel_freq_list)\n        return [pd.Series(list(t)) for t in zip(*x)]  # dark magic\n\n    return _generate\n</code></pre>"},{"location":"api-reference/#gecko.generator.from_normal_distribution","title":"<code>from_normal_distribution(mean=0, sd=1, precision=6, rng=None)</code>","text":"<p>Generate data from a normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>mean of the normal distribution</p> <code>0</code> <code>sd</code> <code>float</code> <p>standard deviation of the normal distribution</p> <code>1</code> <code>precision</code> <code>int</code> <p>decimal precision of the numbers generated from the normal distribution</p> <code>6</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>function returning list with numbers drawn from a normal distribution formatted as strings</p> Source code in <code>gecko/generator.py</code> <pre><code>def from_normal_distribution(\n    mean: float = 0,\n    sd: float = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Generator:\n    \"\"\"\n    Generate data from a normal distribution.\n\n    Args:\n        mean: mean of the normal distribution\n        sd: standard deviation of the normal distribution\n        precision: decimal precision of the numbers generated from the normal distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a normal distribution formatted as strings\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    format_str = f\"%.{precision}f\"\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        return [pd.Series(np.char.mod(format_str, rng.normal(mean, sd, count)))]\n\n    return _generate\n</code></pre>"},{"location":"api-reference/#gecko.generator.from_uniform_distribution","title":"<code>from_uniform_distribution(low=0, high=1, precision=6, rng=None)</code>","text":"<p>Generate data from a uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>low</code> <code>Union[int, float]</code> <p>lower limit of uniform distribution (inclusive)</p> <code>0</code> <code>high</code> <code>Union[int, float]</code> <p>upper limit of uniform distribution (exclusive)</p> <code>1</code> <code>precision</code> <code>int</code> <p>decimal precision of the numbers generated from the uniform distribution</p> <code>6</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Generator</code> <p>function returning list with numbers drawn from a uniform distribution formatted as strings</p> Source code in <code>gecko/generator.py</code> <pre><code>def from_uniform_distribution(\n    low: _t.Union[int, float] = 0,\n    high: _t.Union[int, float] = 1,\n    precision: int = 6,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Generator:\n    \"\"\"\n    Generate data from a uniform distribution.\n\n    Args:\n        low: lower limit of uniform distribution (inclusive)\n        high: upper limit of uniform distribution (exclusive)\n        precision: decimal precision of the numbers generated from the uniform distribution\n        rng: random number generator to use\n\n    Returns:\n        function returning list with numbers drawn from a uniform distribution formatted as strings\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    format_str = f\"%.{precision}f\"\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        return [pd.Series(np.char.mod(format_str, rng.uniform(low, high, count)))]\n\n    return _generate\n</code></pre>"},{"location":"api-reference/#gecko.generator.to_data_frame","title":"<code>to_data_frame(generator_lst, count)</code>","text":"<p>Generate data frame by using multiple generators at once. Column names must be mapped to their respective generators. A generator can be assigned to one or multiple column names, but it must always match the amount of series that the generator returns.</p> <p>Parameters:</p> Name Type Description Default <code>generator_lst</code> <code>_GeneratorSpec</code> <p>list of column names to generators</p> required <code>count</code> <code>int</code> <p>amount of records to generate</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>data frame with columns and rows generated as specified</p> Source code in <code>gecko/generator.py</code> <pre><code>def to_data_frame(\n    generator_lst: _GeneratorSpec,\n    count: int,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate data frame by using multiple generators at once.\n    Column names must be mapped to their respective generators.\n    A generator can be assigned to one or multiple column names, but it must always match the amount of series\n    that the generator returns.\n\n    Args:\n        generator_lst: list of column names to generators\n        count: amount of records to generate\n\n    Returns:\n        data frame with columns and rows generated as specified\n    \"\"\"\n    if len(generator_lst) == 0:\n        raise ValueError(\"generator list may not be empty\")\n\n    if count &lt;= 0:\n        raise ValueError(f\"amount of rows must be positive, is {count}\")\n\n    col_to_srs_dict: dict[str, pd.Series] = {}\n\n    for col_to_gen_def in generator_lst:\n        gen_col_names, gen = col_to_gen_def\n\n        # if a single string is provided, concat by wrapping it into a list\n        if isinstance(gen_col_names, str):\n            gen_col_names = (gen_col_names,)\n\n        # generate values\n        gen_col_values = gen(count)\n\n        # check that the generator returned as many columns as expected\n        if len(gen_col_values) != len(gen_col_names):\n            raise ValueError(\n                f\"generator returned {len(gen_col_values)} columns, but requires {len(gen_col_names)} to \"\n                f\"fill column(s) for: {','.join(gen_col_names)}\"\n            )\n\n        # assign name to series\n        for i in range(len(gen_col_values)):\n            col_to_srs_dict[gen_col_names[i]] = gen_col_values[i]\n\n    # finally create df from the list of named series\n    return pd.DataFrame(data=col_to_srs_dict)\n</code></pre>"},{"location":"api-reference/#mutator","title":"Mutator","text":"<p>The mutator module provides mutator functions for mutating data. These mutators implement common error sources such as typos based on keymaps, random edit errors and more.</p>"},{"location":"api-reference/#gecko.mutator.mutate_data_frame","title":"<code>mutate_data_frame(df_in, mutator_lst)</code>","text":"<p>Mutate a data frame by applying several mutators on select columns. This function takes a list which contains columns and mutators that are assigned to them. A column may be assigned a single mutator, a mutator with a probability, a list of mutators where each is applied with the same probability, and a list of weighted mutators where each is applied with its assigned probability.</p> <p>Parameters:</p> Name Type Description Default <code>df_in</code> <code>DataFrame</code> <p>data frame to mutate</p> required <code>mutator_lst</code> <code>_MutatorSpec</code> <p>list of columns with their mutator assignments</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>data frame with columns mutated as specified</p> Source code in <code>gecko/mutator.py</code> <pre><code>def mutate_data_frame(\n    df_in: pd.DataFrame,\n    mutator_lst: _MutatorSpec,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Mutate a data frame by applying several mutators on select columns.\n    This function takes a list which contains columns and mutators that are assigned to them.\n    A column may be assigned a single mutator, a mutator with a probability, a list of mutators where each is applied\n    with the same probability, and a list of weighted mutators where each is applied with its assigned probability.\n\n    Args:\n        df_in: data frame to mutate\n        mutator_lst: list of columns with their mutator assignments\n\n    Returns:\n        data frame with columns mutated as specified\n    \"\"\"\n\n    df_out = df_in.copy()\n\n    for col_to_mut_def in mutator_lst:\n        column_spec, mutator_spec = col_to_mut_def\n\n        # convert to list if there is only one column specified\n        if isinstance(column_spec, str):\n            column_spec = (column_spec,)\n\n        # check that each column name is valid\n        for column_name in column_spec:\n            if column_name not in df_out.columns:\n                raise ValueError(f\"column `{column_name}` does not exist, must be one of `{','.join(df_in.columns)}`\")\n\n        # if the column is assigned a mutator, assign it a 100% weight and wrap it into a list\n        if callable(mutator_spec):\n            mutator_spec = [(1.0, mutator_spec)]\n\n        # if the column is assigned a tuple, wrap it into a list\n        if _is_weighted_mutator_tuple(mutator_spec):\n            mutator_spec = [mutator_spec]\n\n        # next step is to check the entries of the list. so if the spec has not been converted\n        # to a list yet, then something went wrong.\n        if not isinstance(mutator_spec, list):\n            raise ValueError(\n                f\"invalid type `{type(mutator_spec)}` for mutator definition \" f\"of column `{', '.join(column_spec)}`\"\n            )\n\n        # if the list contains functions only, apply them all with 1.0 probability\n        if all(callable(c) for c in mutator_spec):\n            mutator_spec = [(1.0, mutator) for mutator in mutator_spec]\n\n        # if the end result is not a list of weighted mutators for each column, abort\n        if not _is_weighted_mutator_tuple_list(mutator_spec):\n            raise ValueError(\"malformed mutator definition\")\n\n        srs_lst_out = [df_out[column_name] for column_name in column_spec]\n\n        for weighted_mut in mutator_spec:\n            mut_p, mut_fn = weighted_mut\n\n            if mut_p &lt;= 0 or mut_p &gt; 1:\n                raise ValueError(\"probability for mutator must be in range of (0, 1]\")\n\n            srs_lst_out = mut_fn(srs_lst_out, mut_p)\n\n        for mut_srs_idx, mut_srs in enumerate(srs_lst_out):\n            col_name = column_spec[mut_srs_idx]\n            df_out[col_name] = mut_srs\n\n    return df_out\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_categorical_values","title":"<code>with_categorical_values(data_source, value_column=0, encoding='utf-8', delimiter=',', rng=None)</code>","text":"<p>Mutate series by replacing values with another from a list of categorical values. This mutator reads all unique values from a singular column. All values within a series will be replaced with a different random value from this column. If the value column is provided as a string, and a path to a CSV file is provided to this function, then it is automatically assumed that the CSV file has a header row.</p> <p>Parameters:</p> Name Type Description Default <code>data_source</code> <code>Union[PathLike, str, DataFrame]</code> <p>path to CSV file or data frame containing values</p> required <code>value_column</code> <code>Union[str, int]</code> <p>name or index of value column</p> <code>0</code> <code>encoding</code> <code>str</code> <p>character encoding of the CSV file</p> <code>'utf-8'</code> <code>delimiter</code> <code>str</code> <p>column delimiter of the CSV file</p> <code>','</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by replacing values with a different one from a limited set of permitted values</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_categorical_values(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    value_column: _t.Union[str, int] = 0,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing values with another from a list of categorical values.\n    This mutator reads all unique values from a singular column.\n    All values within a series will be replaced with a different random value from this column.\n    If the value column is provided as a string, and a path to a CSV file is provided to this\n    function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing values\n        value_column: name or index of value column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by replacing values with a different one from a limited set of permitted values\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    if not isinstance(value_column, str) and not isinstance(value_column, int):\n        raise ValueError(\"value column must be either a string or an integer\")\n\n    if isinstance(data_source, pd.DataFrame):\n        df = data_source\n    else:\n        header = isinstance(value_column, str)\n\n        # read csv file\n        df = pd.read_csv(\n            data_source,\n            header=0 if header else None,\n            dtype=str,\n            usecols=[value_column],\n            keep_default_na=False,\n            sep=delimiter,\n            encoding=encoding,\n        )\n\n    # fetch unique values\n    arr_unique_values = np.array(sorted(df.loc[:, value_column].unique()))\n\n    if len(arr_unique_values) &lt; 2:\n        raise ValueError(f\"column must contain at least two unique values, has {len(arr_unique_values)}\")\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        # create copy\n        srs_out = srs.copy(deep=True)\n        # track which rows contain a value that can be mutated\n        srs_rows_to_mutate = pd.Series([False] * len(srs), index=srs.index)\n\n        # update by checking which rows contain a candidate value\n        for val in arr_unique_values:\n            srs_rows_to_mutate |= srs == val\n\n        # check rows that can be mutated\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        # warn if p cannot be met\n        if p_actual &lt; p:\n            _warn_p(with_categorical_values.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # perform selection\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        for val in arr_unique_values:\n            # fetch all rows that match the value\n            srs_this_val = srs_rows_to_mutate &amp; (srs == val)\n            rows_to_mutate_count = srs_this_val.sum()\n\n            # skip if no rows match\n            if rows_to_mutate_count == 0:\n                continue\n\n            # get the set of unique values minus the one that is currently processed\n            arr_unique_values_without_this = np.setdiff1d(arr_unique_values, val)\n            # perform the update\n            srs_out.loc[srs_this_val] = rng.choice(arr_unique_values_without_this, size=rows_to_mutate_count)\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_cldr_keymap_file","title":"<code>with_cldr_keymap_file(cldr_path, charset=None, rng=None)</code>","text":"<p>Mutate series by randomly introducing typos. Potential typos are sourced from a Common Locale Data Repository (CLDR) keymap. Any character may be replaced with one of its horizontal or vertical neighbors on a keyboard. They may also be replaced with its upper- or lowercase variant. It is possible for a string to not be modified if a selected character has no possible replacements. If the <code>charset</code> parameter is <code>None</code>, then any character present on the keymap may be mutated.</p> <p>Parameters:</p> Name Type Description Default <code>cldr_path</code> <code>Union[PathLike, str]</code> <p>path to CLDR keymap file</p> required <code>charset</code> <code>Optional[Union[str, list[str]]]</code> <p>character string or list of characters that may be mutated</p> <code>None</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series using a keymap</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_cldr_keymap_file(\n    cldr_path: _t.Union[PathLike, str],\n    charset: _t.Optional[_t.Union[str, list[str]]] = None,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly introducing typos.\n    Potential typos are sourced from a Common Locale Data Repository (CLDR) keymap.\n    Any character may be replaced with one of its horizontal or vertical neighbors on a keyboard.\n    They may also be replaced with its upper- or lowercase variant.\n    It is possible for a string to not be modified if a selected character has no possible replacements.\n    If the `charset` parameter is `None`, then any character present on the keymap may be mutated.\n\n    Args:\n        cldr_path: path to CLDR keymap file\n        charset: character string or list of characters that may be mutated\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using a keymap\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # break string of chars up into a list of chars\n    if charset is not None:\n        if isinstance(charset, str):\n            charset = list(charset)\n\n    with Path(cldr_path).open(mode=\"r\", encoding=\"utf-8\") as f:\n        tree = etree.parse(f)\n\n    root = tree.getroot()\n\n    # compute the row and column count\n    max_row, max_col = 0, 0\n\n    for map_node in root.iterfind(\"./keyMap/map\"):\n        # decode_iso_kb_pos is cached so calling this repeatedly shouldn't have an impact on performance\n        kb_row, kb_col = _cldr.decode_iso_kb_pos(map_node.get(\"iso\"))\n        max_row = max(max_row, kb_row)\n        max_col = max(max_col, kb_col)\n\n    kb_map = np.chararray(\n        shape=(\n            max_row + 1,\n            max_col + 1,\n            2,\n        ),  # + 1 because rows and cols are zero-indexed, 2 to accommodate shift\n        itemsize=1,  # each cell holds one unicode char\n        unicode=True,\n    )\n    kb_map[:] = \"\"  # initialize with empty strings\n\n    # remember the kb pos for each character\n    kb_char_to_kb_pos_dict: dict[str, (int, int, int)] = {}\n\n    for key_map_node in root.iterfind(\"./keyMap\"):\n        key_map_mod = key_map_node.get(\"modifiers\")\n\n        if key_map_mod is None:\n            kb_mod = 0\n        elif key_map_mod == \"shift\":\n            kb_mod = 1\n        else:\n            continue\n\n        for map_node in key_map_node.iterfind(\"./map\"):\n            kb_row, kb_col = _cldr.decode_iso_kb_pos(map_node.get(\"iso\"))\n            kb_char = _cldr.unescape_kb_char(map_node.get(\"to\"))\n\n            # check that char is listed if charset of permitted chars is provided\n            if charset is not None and kb_char not in charset:\n                continue\n\n            kb_char_to_kb_pos_dict[kb_char] = (kb_row, kb_col, kb_mod)\n            kb_map[kb_row, kb_col, kb_mod] = kb_char\n\n    # map each character with other nearby characters that it could be replaced with due to a typo\n    kb_char_to_candidates_dict: dict[str, str] = {}\n\n    with np.nditer(kb_map, flags=[\"multi_index\"], op_flags=[[\"readonly\"]]) as it:\n        for kb_char in it:\n            # iterator returns str as array of unicode chars. convert it to str.\n            kb_char = str(kb_char)\n\n            # skip keys that don't have a character assigned to them\n            if kb_char == \"\":\n                continue\n\n            kb_pos = it.multi_index\n            # noinspection PyTypeChecker\n            kb_pos_neighbors = _cldr.get_neighbor_kb_pos_for(kb_pos, max_row, max_col)\n            kb_char_candidates = set()\n\n            for kb_pos_neighbor in kb_pos_neighbors:\n                kb_char_candidate = kb_map[kb_pos_neighbor]\n\n                # check that the key pos has a char assigned to it. it may also happen that the char is the same\n                # despite the kb modifier. that needs to be accounted for.\n                if kb_char_candidate != \"\" and kb_char_candidate != kb_char:\n                    kb_char_candidates.add(kb_char_candidate)\n\n            # check that there are any candidates\n            if len(kb_char_candidates) &gt; 0:\n                kb_char_to_candidates_dict[kb_char] = \"\".join(\n                    sorted(list(kb_char_candidates))  # needs to be sorted to ensure reproducibility\n                )\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        _check_probability_in_bounds(p)\n\n        srs_out = srs.copy(deep=True)\n        srs_len = len(srs_out)\n\n        # make sure it aligns with the original index\n        srs_candidate_chars = pd.Series([\"\"] * srs_len, index=srs_out.index)\n\n        for candidate_char in kb_char_to_candidates_dict.keys():\n            # check for rows where candidate charis president\n            srs_contains_candidate_char = srs.str.contains(candidate_char, regex=False)\n            # add it as a candidate char to all applicable rows\n            srs_candidate_chars.loc[srs_contains_candidate_char] += candidate_char\n\n        # create a mask that selects all rows affected by mutation\n        # first drop all rows which have no candidate chars\n        srs_selected_for_mutation = srs_candidate_chars != \"\"\n\n        # now check if the desired p value can be reached, warn if not\n        p_candidates = srs_selected_for_mutation.sum() / srs_len\n\n        if p_candidates &lt; p:\n            _warn_p(with_cldr_keymap_file.__name__, p, p_candidates)\n\n        # select p for all eligible rows, avoid values &gt; 1\n        p_subset_select = min(1.0, p / p_candidates)\n        # draw random rows to actually perform mutation on\n        arr_rng_vals = rng.random(size=srs_selected_for_mutation.sum())\n        # update the mutation mask (it may happen that rows that were True might flip to False)\n        srs_selected_for_mutation.loc[srs_selected_for_mutation] = arr_rng_vals &lt; p_subset_select\n        # this is now the amount of all rows that will definitely be mutated\n        rows_to_mutate_count = srs_selected_for_mutation.sum()\n\n        # now srs_selected_for_mutation accurately represents the rows to perform mutation on, satisfying p\n        # and rows that could actually be affected\n        srs_candidates_selected = pd.Series([\"\"] * srs_len, index=srs.index)\n\n        # draw random candidate chars\n        arr_rng_vals = rng.random(size=rows_to_mutate_count)\n        arr_rng_idxs = np.floor(srs_candidate_chars.loc[srs_selected_for_mutation].str.len() * arr_rng_vals).astype(int)\n\n        # iterate over all unique indices and select the char at the i-th position\n        for idx in arr_rng_idxs.unique():\n            idx_mask = arr_rng_idxs == idx\n            srs_this_idx = srs_candidate_chars.loc[srs_selected_for_mutation].loc[idx_mask]\n            srs_candidates_selected.update(srs_this_idx.str[idx])\n\n        # now do the same process for replacement chars\n        srs_replacements_selected = pd.Series([\"\"] * srs_len, index=srs.index)\n\n        for candidate_char in srs_candidates_selected.loc[srs_selected_for_mutation].unique():\n            srs_this_candidate_char = srs_candidates_selected == candidate_char\n            # count all affected rows\n            candidate_char_count = srs_this_candidate_char.sum()\n            # fetch replacement chars\n            replacement_chars = kb_char_to_candidates_dict[candidate_char]\n            # draw random replacement chars for each row\n            arr_rng_repl = rng.choice(list(replacement_chars), size=candidate_char_count)\n            # and update the replacement char series\n            srs_replacements_selected.loc[srs_this_candidate_char] = arr_rng_repl\n\n        # and now we do the actual replacements\n        for candidate_char in srs_candidates_selected.loc[srs_selected_for_mutation].unique():\n            # filter by global mask and rows that contain this candidate char\n            srs_this_replacement_char = srs_selected_for_mutation &amp; (srs_candidates_selected == candidate_char)\n\n            for replacement_char in srs_replacements_selected.loc[srs_this_replacement_char].unique():\n                srs_out.update(\n                    srs_out.loc[srs_this_replacement_char].str.replace(candidate_char, replacement_char, n=1)\n                )\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float) -&gt; list[pd.Series]:\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_datetime_offset","title":"<code>with_datetime_offset(max_delta, unit, dt_format, prevent_wraparound=False, rng=None)</code>","text":"<p>Mutate series by treating their contents it as datetime information and offsetting it by random amounts. The delta and the unit specify which datetime field should be affected, where possible values are <code>d</code> and <code>days</code>, <code>h</code> and <code>hours</code>, <code>m</code> and <code>minutes</code>, <code>s</code> and <code>seconds</code>. The datetime format must include the same format codes as specified in the <code>datetime</code> Python module for the <code>strftime</code> function. By setting <code>prevent_wraparound</code> to <code>True</code>, this mutator will not apply a mutation if it will cause an unrelated field to change its value, e.g. when subtracting a day from July 1st, 2001.</p> <p>Parameters:</p> Name Type Description Default <code>max_delta</code> <code>int</code> <p>maximum amount of units to change by</p> required <code>unit</code> <code>DateTimeUnit</code> <p>affected datetime field</p> required <code>dt_format</code> <code>str</code> <p>input and output datetime format</p> required <code>prevent_wraparound</code> <code>bool</code> <p><code>True</code> if unrelated fields should not be modified, <code>False</code> otherwise</p> <code>False</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by applying random date and time offsets to them</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_datetime_offset(\n    max_delta: int,\n    unit: _gt.DateTimeUnit,\n    dt_format: str,\n    prevent_wraparound: bool = False,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by treating their contents it as datetime information and offsetting it by random amounts.\n    The delta and the unit specify which datetime field should be affected, where possible values are\n    `d` and `days`, `h` and `hours`, `m` and `minutes`, `s` and `seconds`.\n    The datetime format must include the same format codes as specified in the `datetime` Python module for the\n    `strftime` function.\n    By setting `prevent_wraparound` to `True`, this mutator will not apply a mutation if it will cause an\n    unrelated field to change its value, e.g. when subtracting a day from July 1st, 2001.\n\n    Args:\n        max_delta: maximum amount of units to change by\n        unit: affected datetime field\n        dt_format: input and output datetime format\n        prevent_wraparound: `True` if unrelated fields should not be modified, `False` otherwise\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by applying random date and time offsets to them\n    \"\"\"\n    if max_delta &lt;= 0:\n        raise ValueError(f\"delta must be positive, is {max_delta}\")\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_dt = pd.to_datetime(srs, format=dt_format, errors=\"raise\")\n        srs_dt_out = srs_dt.copy(deep=True)\n\n        # select rows that should be mutated\n        arr_rows_to_mutate = rng.random(size=len(srs)) &lt; p\n\n        # draw random amount of time units for rows to modify\n        arr_rng_vals = rng.integers(low=1, high=max_delta, size=len(srs_dt), endpoint=True) * rng.choice(\n            (-1, 1), size=len(srs_dt)\n        )\n\n        for sgn in (-1, 1):\n            for val in range(1, max_delta + 1):\n                # compute the delta\n                this_delta = sgn * val\n                # wrap it into a timedelta\n                this_timedelta = pd.Timedelta(this_delta, _gt.convert_gecko_date_time_unit_to_pandas(unit))\n                # select all rows that have this delta applied to them\n                this_srs_mask = (arr_rng_vals == this_delta) &amp; arr_rows_to_mutate\n                # update rows\n                srs_dt_out.loc[this_srs_mask] += this_timedelta\n\n                # patch stuff if it wrapped around on accident\n                if prevent_wraparound:\n                    if unit in (\"days\", \"d\"):\n                        wraparound_patch_mask = srs_dt_out.dt.month != srs_dt.dt.month\n                    elif unit in (\"hours\", \"h\"):\n                        wraparound_patch_mask = srs_dt_out.dt.day != srs_dt.dt.day\n                    elif unit in (\"minutes\", \"m\"):\n                        wraparound_patch_mask = srs_dt_out.dt.hour != srs_dt.dt.hour\n                    elif unit in (\"seconds\", \"s\"):\n                        wraparound_patch_mask = srs_dt_out.dt.minute != srs_dt.dt.minute\n                    else:\n                        raise ValueError(f\"unrecognized unit: `{unit}`\")\n\n                    # use original values (could probably be solved a bit more elegantly?)\n                    srs_dt_out.loc[wraparound_patch_mask] = srs_dt.loc[wraparound_patch_mask]\n\n        # check if all rows that were marked for mutation actually got mutated\n        srs_mutated_rows = srs_dt.loc[arr_rows_to_mutate] != srs_dt_out.loc[arr_rows_to_mutate]\n        p_actual = srs_mutated_rows.sum() / len(srs)\n\n        if not srs_mutated_rows.all():\n            _warn_p(with_datetime_offset.__name__, p, p_actual)\n\n        return srs_dt_out.dt.strftime(dt_format)\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_delete","title":"<code>with_delete(rng=None)</code>","text":"<p>Mutate series by randomly deleting characters.</p> <p>Parameters:</p> Name Type Description Default <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by deleting random characters</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_delete(rng: _t.Optional[np.random.Generator] = None) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly deleting characters.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by deleting random characters\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n\n        # limit to strings that have at least a single character\n        srs_rows_to_mutate = srs.str.len() &gt;= 1\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        if p_actual &lt; p:\n            _warn_p(with_delete.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # select subset of rows to mutate\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        # count rows that will be mutated\n        rows_to_mutate_count = srs_rows_to_mutate.sum()\n\n        # generate random indices\n        arr_rng_vals = rng.random(size=rows_to_mutate_count)\n        arr_rng_idx = np.floor(srs.loc[srs_rows_to_mutate].str.len() * arr_rng_vals).astype(int)\n\n        # perform the character deletion (don't need to dropna() here)\n        for del_idx in arr_rng_idx.unique():\n            srs_this_idx = srs.loc[srs_rows_to_mutate].loc[arr_rng_idx == del_idx]\n            srs_out.update(srs_this_idx.str.slice_replace(del_idx, del_idx + 1, \"\"))\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_function","title":"<code>with_function(func, rng=None, *args, **kwargs)</code>","text":"<p>Mutate series using an arbitrary function that mutates a single value at a time.</p> Notes <p>This function should be used sparingly since it is not vectorized. Only use it for testing purposes or if performance is not important.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[Concatenate[str, _P], str]</code> <p>function to mutate values with</p> required <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <code>*args</code> <code>object</code> <p>positional arguments to pass to <code>func</code></p> <code>()</code> <code>**kwargs</code> <code>object</code> <p>keyword arguments to pass to <code>func</code></p> <code>{}</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series using the custom function</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_function(\n    func: _t.Callable[_te.Concatenate[str, _P], str],\n    rng: _t.Optional[np.random.Generator] = None,\n    *args: object,\n    **kwargs: object,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series using an arbitrary function that mutates a single value at a time.\n\n    Notes:\n        This function should be used sparingly since it is not vectorized.\n        Only use it for testing purposes or if performance is not important.\n\n    Args:\n        func: function to mutate values with\n        rng: random number generator to use\n        *args: positional arguments to pass to `func`\n        **kwargs: keyword arguments to pass to `func`\n\n    Returns:\n        function that mutates series using the custom function\n    \"\"\"\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _bound_apply(val: object) -&gt; str:\n        x = func(str(val), *args, **kwargs)\n        return str(x)\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n        srs_rows_to_mutate = pd.Series(rng.random(size=len(srs)) &lt; p, index=srs.index)\n        srs_out.update(srs.loc[srs_rows_to_mutate].apply(_bound_apply))\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_generator","title":"<code>with_generator(generator, mode, join_with=' ', rng=None)</code>","text":"<p>Mutate series by replacing its content by appending, prepending or replacing it with data from another generator. A string to join generated data with when appending or prepending can be provided. Using <code>{}</code> in the <code>join_with</code> parameter will cause it to be replaced by generated values. Only the first occurrence of <code>{}</code> will be replaced.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator</code> <p>generator to source data from</p> required <code>mode</code> <code>Literal['prepend', 'append', 'replace']</code> <p>either append, prepend or replace</p> required <code>join_with</code> <code>str</code> <p>string to join present and generated data with</p> <code>' '</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series using another generator</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_generator(\n    generator: _gt.Generator,\n    mode: _t.Literal[\"prepend\", \"append\", \"replace\"],\n    join_with: str = \" \",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its content by appending, prepending or replacing it with data from another generator.\n    A string to join generated data with when appending or prepending can be provided.\n    Using `{}` in the `join_with` parameter will cause it to be replaced by generated values.\n    Only the first occurrence of `{}` will be replaced.\n\n    Args:\n        generator: generator to source data from\n        mode: either append, prepend or replace\n        join_with: string to join present and generated data with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using another generator\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    # {} denotes the place where the generated values should be inserted (only when prepending or appending)\n    join_with_before, join_with_after = \" \", \" \"\n    join_with_parts = join_with.split(\"{}\", maxsplit=1)\n\n    if len(join_with_parts) == 1:\n        # no {} could be found, prepend or append join character as usual\n        if mode == \"prepend\":\n            join_with_before, join_with_after = \"\", join_with_parts[0]\n        elif mode == \"append\":\n            join_with_before, join_with_after = join_with_parts[0], \"\"\n    else:\n        # otherwise fill in characters before and after {}\n        # [:2] avoids errors in destructuring (although len(join_with_parts) should always be 2...)\n        join_with_before, join_with_after = join_with_parts[:2]\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        # check that all series are of the same length\n        srs_lst_len_set = set([len(srs) for srs in srs_lst])\n\n        if len(srs_lst_len_set) != 1:\n            raise ValueError(\"series do not have the same length\")\n\n        # use this length as a param for the generator later\n        srs_len = srs_lst_len_set.pop()\n\n        # check that the indices of all input series are aligned\n        if len(srs_lst) &gt; 1:\n            indices_aligned = [(srs_lst[0].index == srs_lst[i].index).all() for i in range(1, len(srs_lst))]\n\n            if not all(indices_aligned):\n                raise ValueError(\"indices of input series are not aligned\")\n\n        arr_rows_to_mutate = rng.random(size=srs_len) &lt; p\n        rows_to_mutate_count = arr_rows_to_mutate.sum()\n\n        srs_gen_lst = generator(rows_to_mutate_count)\n\n        # check that the generator returns as many series as provided to the mutator.\n        if len(srs_lst) != len(srs_gen_lst):\n            raise ValueError(\n                f\"generator must generate as many series as provided to the mutator: \"\n                f\"got {len(srs_gen_lst)}, expected {len(srs_lst)}\"\n            )\n\n        # align indices with the input series index. use ffill to\n        # avoid nas when reindexing.\n        srs_gen_lst_aligned = [srs.reindex(srs_lst[i].index, method=\"ffill\") for i, srs in enumerate(srs_gen_lst)]\n\n        srs_lst_out = [srs.copy(deep=True) for srs in srs_lst]\n\n        # perform the actual data mutation (this is where index alignment matters)\n        for i, srs_gen in enumerate(srs_gen_lst_aligned):\n            if mode == \"replace\":\n                srs_lst_out[i].loc[arr_rows_to_mutate] = srs_gen\n            elif mode == \"prepend\":\n                srs_lst_out[i].loc[arr_rows_to_mutate] = (\n                    join_with_before + srs_gen + join_with_after + srs_lst_out[i][:]\n                )\n            elif mode == \"append\":\n                srs_lst_out[i].loc[arr_rows_to_mutate] += join_with_before + srs_gen + join_with_after\n            else:\n                raise ValueError(f\"invalid mode: `{mode}`\")\n\n        return srs_lst_out\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_group","title":"<code>with_group(mutator_lst, rng=None)</code>","text":"<p>Mutate series by applying multiple mutators on it. The mutators are applied in the order that they are provided in to this function. When providing a list of mutators, each row will be affected by each mutator with an equal probability. When providing a list of weighted mutators, each row will be affected by each mutator with the specified probabilities. If the probabilities do not sum up to 1, an additional mutator is added which does not modify input data.</p> <p>Parameters:</p> Name Type Description Default <code>mutator_lst</code> <code>Union[list[Mutator], list[_WeightedMutatorDef]]</code> <p>list of mutators or weighted mutators</p> required <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series using multiple mutually exclusive mutators at once</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_group(\n    mutator_lst: _t.Union[list[_gt.Mutator], list[_WeightedMutatorDef]],\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by applying multiple mutators on it.\n    The mutators are applied in the order that they are provided in to this function.\n    When providing a list of mutators, each row will be affected by each mutator with an equal probability.\n    When providing a list of weighted mutators, each row will be affected by each mutator with the\n    specified probabilities.\n    If the probabilities do not sum up to 1, an additional mutator is added which does not modify input data.\n\n    Args:\n        mutator_lst: list of mutators or weighted mutators\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series using multiple mutually exclusive mutators at once\n    \"\"\"\n    if all(callable(m) for m in mutator_lst):\n        p_idx = 1.0 / len(mutator_lst)\n        mutator_lst = [(p_idx, m) for m in mutator_lst]\n\n    if not _is_weighted_mutator_tuple_list(mutator_lst):\n        raise ValueError(\"invalid argument, must be a list of mutators or weighted mutators\")\n\n    p_sum = sum(t[0] for t in mutator_lst)\n\n    if p_sum &gt; 1:\n        raise ValueError(f\"sum of weights must not be higher than 1, is {p_sum}\")\n\n    if p_sum &lt;= 0:\n        raise ValueError(f\"sum of weights must be higher than 0, is {p_sum}\")\n\n    # pad probabilities\n    if p_sum != 1:\n        mutator_lst.append((1 - p_sum, with_noop()))\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    p_vals: tuple[_t.Union[int, float], ...]\n    mut_lst: tuple[_gt.Mutator, ...]\n    p_vals, mut_lst = zip(*mutator_lst)\n\n    for mut_idx, p_idx in enumerate(p_vals):\n        if p_idx &lt;= 0:\n            raise ValueError(f\"weight of mutator at index {mut_idx} must be higher than zero, is {p_idx}\")\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n\n        # check that all series have the same length\n        if len(set(len(s) for s in srs_lst)) != 1:\n            raise ValueError(\"series do not have the same length\")\n\n        srs_len = len(srs_lst[0])\n        srs_lst_out = [srs.copy(deep=True) for srs in srs_lst]\n\n        # each row gets an index of the applied mutator\n        arr_rows_to_mutate = rng.random(size=srs_len) &lt; p\n        arr_mut_idx = np.arange(len(mutator_lst))\n        arr_mut_per_row = rng.choice(arr_mut_idx, p=p_vals, size=srs_len)\n\n        # iterate over each mutator\n        for i in arr_mut_idx:\n            mutator = mut_lst[i]\n            # select all rows that have this mutator applied to it\n            msk_this_mut = arr_rows_to_mutate &amp; (arr_mut_per_row == i)\n            srs_mut_lst = mutator([srs[msk_this_mut] for srs in srs_lst_out], 1.0)\n\n            for j, srs_mut in enumerate(srs_mut_lst):\n                srs_lst_out[j].update(srs_mut)\n\n        return srs_lst_out\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_insert","title":"<code>with_insert(charset=string.ascii_letters, rng=None)</code>","text":"<p>Mutate series by inserting random characters. The characters are drawn from the provided charset.</p> <p>Parameters:</p> Name Type Description Default <code>charset</code> <code>Union[str, list[str]]</code> <p>character string or list of characters to sample from</p> <code>ascii_letters</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by injecting random characters</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_insert(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by inserting random characters.\n    The characters are drawn from the provided charset.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by injecting random characters\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    if isinstance(charset, str):\n        charset = list(charset)\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n\n        # select rows (don't need to do p-check because a new character can always be appended)\n        srs_rows_to_mutate = pd.Series(rng.random(size=len(srs)) &lt; p, index=srs.index)\n\n        # count rows that will be mutated\n        rows_to_mutate_count = srs_rows_to_mutate.sum()\n\n        # generate random indices to insert values at\n        arr_rng_vals = rng.random(size=rows_to_mutate_count)\n        arr_ins_idx = np.floor(\n            (srs.loc[srs_rows_to_mutate].str.len() + 1) * arr_rng_vals  # +1 because letters can be inserted at the end\n        ).astype(int)\n\n        # generate random characters to insert\n        arr_rng_chars = rng.choice(charset, size=rows_to_mutate_count)\n        # create view on values to mutate\n        srs_in_rows = srs.loc[srs_rows_to_mutate]\n\n        for ins_idx in arr_ins_idx.unique():\n            # select all rows that have an insertion at this index\n            arr_this_idx = arr_ins_idx == ins_idx\n            srs_this_idx = srs_in_rows.loc[arr_this_idx]\n            # then update all affected rows\n            srs_out.update(srs_this_idx.str[:ins_idx] + arr_rng_chars[arr_this_idx] + srs_this_idx.str[ins_idx:])\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_lowercase","title":"<code>with_lowercase(rng=None)</code>","text":"<p>Mutate series by converting its contents to lowercase.</p> <p>Parameters:</p> Name Type Description Default <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by converting its contents to lowercase</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_lowercase(rng: _t.Optional[np.random.Generator] = None) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to lowercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to lowercase\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n\n        # limit series to strings that are not all uppercase yet\n        srs_rows_to_mutate = ~srs.str.islower()\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        if p_actual &lt; p:\n            _warn_p(with_lowercase.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # select subset of rows to mutate\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        # update selected rows\n        srs_out.update(srs.loc[srs_rows_to_mutate].str.lower())\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_missing_value","title":"<code>with_missing_value(value='', rng=None)</code>","text":"<p>Mutate series by replacing its values with a representative \"missing\" value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>\"missing\" value to replace select entries with</p> <code>''</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by overwriting it with a \"missing\" value</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_missing_value(\n    value: str = \"\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by replacing its values with a representative \"missing\" value.\n\n    Args:\n        value: \"missing\" value to replace select entries with\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by overwriting it with a \"missing\" value\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n\n        srs_rows_to_mutate = srs != value\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        if p_actual &lt; p:\n            _warn_p(with_missing_value.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # select subset of rows to mutate\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        # update rows to mutate\n        srs_out.loc[srs_rows_to_mutate] = value\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_noop","title":"<code>with_noop()</code>","text":"<p>Mutate series by not mutating it at all. This mutator returns the input series as-is. You might use it to leave a certain percentage of records in a series untouched.</p> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that does not mutate series</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_noop() -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by not mutating it at all.\n    This mutator returns the input series as-is.\n    You might use it to leave a certain percentage of records in a series untouched.\n\n    Returns:\n        function that does not mutate series\n    \"\"\"\n\n    def _mutate(srs_lst: list[pd.Series], p: float) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return srs_lst\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_permute","title":"<code>with_permute(rng=None)</code>","text":"<p>Mutate series by permuting their contents. This function ensures that rows are permuted in such a way that no value remains in the series it originated from.</p> <p>Parameters:</p> Name Type Description Default <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by permuting their contents</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_permute(rng: _t.Optional[np.random.Generator] = None) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by permuting their contents.\n    This function ensures that rows are permuted in such a way that no value remains in the series\n    it originated from.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by permuting their contents\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _filter_permutations(tpl: tuple[int, ...]) -&gt; bool:\n        for idx, val in enumerate(tpl):\n            if idx == val:\n                return False\n\n        return True\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        srs_lst_len = len(srs_lst)\n\n        if srs_lst_len &lt; 2:\n            raise ValueError(\"list must contain at least two series to permute\")\n\n        srs_0_len = len(srs_lst[0])\n\n        for i in range(1, srs_lst_len):\n            if len(srs_lst[i]) != srs_0_len:\n                raise ValueError(\"all series must be of the same length\")\n\n        # nothing to permute\n        if srs_0_len == 0:\n            return srs_lst\n\n        # generate all series index permutations and remove the tuple with all indices in order.\n        # filter out all tuples that keep values from any column in the same column.\n        srs_idx_permutations = sorted(filter(_filter_permutations, itertools.permutations(range(len(srs_lst)))))\n\n        # select rows\n        arr_rows_to_mutate = rng.random(size=srs_0_len) &lt; p\n\n        # choose random index permutations\n        arr_rand_idx_tpl = rng.choice(srs_idx_permutations, size=srs_0_len)\n        # map tuples to each series (zip indices -&gt; convert to array -&gt; wrap in list)\n        arr_idx_per_srs = list(map(np.array, zip(*arr_rand_idx_tpl)))\n\n        srs_lst_out = [srs.copy(deep=True) for srs in srs_lst]\n\n        for i in range(srs_lst_len):\n            for j in range(srs_lst_len):\n                if i == j:\n                    continue\n\n                arr_this_srs = arr_rows_to_mutate &amp; (arr_idx_per_srs[i] == j)\n                srs_lst_out[i].loc[arr_this_srs] = srs_lst[j].loc[arr_this_srs]\n\n        return srs_lst_out\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_phonetic_replacement_table","title":"<code>with_phonetic_replacement_table(data_source, source_column=0, target_column=1, flags_column=2, encoding='utf-8', delimiter=',', rng=None)</code>","text":"<p>Mutate series by randomly replacing character sequences with others that sound similar. The rules for similar-sounding character sequences are sourced from a table. This table must have at least three columns: a source, target and a flag column. A source pattern is mapped to its target under the rules imposed by the provided flags. These flags determine where such a replacement can take place within a string. If no flags are defined, it is implied that this replacement can take place anywhere in a string. Conversely, if <code>^</code>, <code>$</code>, <code>_</code>, or any combination of the three are set, it implies that a replacement can only occur at the start, end or in the middle of a string. If the source, target and flags column are provided as strings, and if a path to a CSV file is provided to this function, then it is automatically assumed that the CSV file has a header row.</p> <p>Parameters:</p> Name Type Description Default <code>data_source</code> <code>Union[PathLike, str, DataFrame]</code> <p>path to CSV file or data frame containing phonetic replacement rules</p> required <code>source_column</code> <code>Union[int, str]</code> <p>name or index of source column</p> <code>0</code> <code>target_column</code> <code>Union[int, str]</code> <p>name or index of target column</p> <code>1</code> <code>flags_column</code> <code>Union[int, str]</code> <p>name or index of flag column</p> <code>2</code> <code>encoding</code> <code>str</code> <p>character encoding of the CSV file</p> <code>'utf-8'</code> <code>delimiter</code> <code>str</code> <p>column delimiter of the CSV file</p> <code>','</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series using phonetic rules sourced from a table</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_phonetic_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[int, str] = 0,\n    target_column: _t.Union[int, str] = 1,\n    flags_column: _t.Union[int, str] = 2,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly replacing character sequences with others that sound similar.\n    The rules for similar-sounding character sequences are sourced from a table.\n    This table must have at least three columns: a source, target and a flag column.\n    A source pattern is mapped to its target under the rules imposed by the provided flags.\n    These flags determine where such a replacement can take place within a string.\n    If no flags are defined, it is implied that this replacement can take place anywhere in a string.\n    Conversely, if `^`, `$`, `_`, or any combination of the three are set, it implies that a replacement\n    can only occur at the start, end or in the middle of a string.\n    If the source, target and flags column are provided as strings, and if a path to a CSV file is\n    provided to this function, then it is automatically assumed that the CSV file has a header row.\n\n    Args:\n        data_source: path to CSV file or data frame containing phonetic replacement rules\n        source_column: name or index of source column\n        target_column: name or index of target column\n        flags_column: name or index of flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n       function that mutates series using phonetic rules sourced from a table\n    \"\"\"\n\n    # list of all flags\n    _all_flags = \"\".join([_PHON_FLAG_START, _PHON_FLAG_END, _PHON_FLAG_MIDDLE])\n\n    def _validate_flags(flags_str: _t.Optional[str]) -&gt; str:\n        \"\"\"Check a string for valid flags. Returns all flags if string is empty, `NaN` or `None`.\"\"\"\n        if pd.isna(flags_str) or flags_str == \"\" or flags_str is None:\n            return _all_flags\n\n        for char in flags_str:\n            if char not in _all_flags:\n                raise ValueError(f\"unknown flag: {char}\")\n\n        return flags_str\n\n    def _new_unknown_flag_error(f: str):\n        return ValueError(f\"invalid state: unknown flag `{f}`\")\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    if type(source_column) is not type(target_column) or type(target_column) is not type(flags_column):\n        raise ValueError(\"source, target and flags columns must be of the same type\")\n\n    # skip check for source and target column bc they are of same type already\n    if not isinstance(flags_column, str) and not isinstance(flags_column, int):\n        raise ValueError(\"source, target and flags columns must be either a string or an integer\")\n\n    if isinstance(data_source, pd.DataFrame):\n        df = data_source\n    else:\n        header = isinstance(flags_column, str)\n\n        # read csv file\n        df = pd.read_csv(\n            data_source,\n            header=0 if header else None,\n            dtype=str,\n            usecols=[source_column, target_column, flags_column],\n            keep_default_na=False,\n            sep=delimiter,\n            encoding=encoding,\n        )\n\n    # parse replacement rules\n    phonetic_replacement_rules: list[_PhoneticReplacementRule] = []\n\n    for _, row in df.iterrows():\n        pattern = row[source_column]\n        replacement = row[target_column]\n        flags = _validate_flags(row[flags_column])\n\n        for flag in flags:\n            phonetic_replacement_rules.append(_PhoneticReplacementRule(pattern, replacement, flag))\n\n    num_rules = len(phonetic_replacement_rules)\n\n    if num_rules == 0:\n        raise ValueError(\"must provide at least one phonetic replacement rule\")\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        # create copy\n        srs_out = srs.copy(deep=True)\n        # create index df\n        df_idx = _dfbitlookup.with_capacity(len(srs), num_rules, index=srs.index)\n\n        # track which rules can be applied to each row\n        for rule_idx, rule in enumerate(phonetic_replacement_rules):\n            if rule.flag == _PHON_FLAG_START:\n                # mark all rows containing this pattern at the start\n                _dfbitlookup.set_index(df_idx, srs.str.startswith(rule.pattern), rule_idx)\n            elif rule.flag == _PHON_FLAG_END:\n                # mark all rows containing this pattern at the end\n                _dfbitlookup.set_index(df_idx, srs.str.endswith(rule.pattern), rule_idx)\n            elif rule.flag == _PHON_FLAG_MIDDLE:\n                _dfbitlookup.set_index(df_idx, srs.str.slice(1, -1).str.contains(rule.pattern), rule_idx)\n            else:\n                raise _new_unknown_flag_error(flag)\n\n        # check rows that can be mutated\n        srs_rows_to_mutate = _dfbitlookup.any_set(df_idx)\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        # warn if p cannot be met\n        if p_actual &lt; p:\n            _warn_p(with_phonetic_replacement_table.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # perform selection\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; min(1.0, p / p_actual)\n\n        # retrieve the frequencies of each rule matching across all rows\n        arr_set_indices = _dfbitlookup.count_bits_per_index(df_idx, num_rules)\n        # keep only indices that have at least one match\n        arr_set_indices = list(filter(lambda tpl: tpl[1] != 0, arr_set_indices))\n        # sort in descending order of frequency. rare replacements are more likely to happen this\n        # way because rows with few replacement options will eventually be guaranteed to have these\n        # replacements applied to them.\n        arr_set_indices.sort(key=lambda tpl: -tpl[1])\n        # keep only the indices\n        arr_rule_idx = np.array([tpl[0] for tpl in arr_set_indices])\n\n        # get amount of set bits per row\n        srs_set_bit_count_per_row = _dfbitlookup.count_bits_per_row(df_idx, num_rules).astype(float)\n        # check which rows are not zero to avoid div by 0\n        srs_count_not_zero = srs_set_bit_count_per_row != 0\n\n        for rule_idx in arr_rule_idx:\n            # retrieve the appropriate rule\n            rule = phonetic_replacement_rules[rule_idx]\n            # draw random values\n            arr_rng_vals = rng.random(size=len(srs))\n\n            # determine the likelihood of each row for being chosen in this iteration\n            srs_rng_prob = srs_set_bit_count_per_row.copy(deep=True)\n            srs_rng_prob[srs_count_not_zero] = 1.0 / srs_rng_prob[srs_count_not_zero]\n\n            # check which rules are affected by this rule\n            srs_selected_rows_mask = (\n                srs_rows_to_mutate  # select eligible rows\n                &amp; (srs == srs_out)  # AND select rows that haven't been mutated yet\n                &amp; (_dfbitlookup.test_index(df_idx, rule_idx))  # AND select rows that match this rule\n                &amp; (arr_rng_vals &lt; srs_rng_prob)  # AND select rows that are randomly selected\n            )\n\n            # increase chance of being picked for rows that match this rule and that\n            # have NOT been selected by chance this time\n            srs_set_bit_count_per_row[_dfbitlookup.test_index(df_idx, rule_idx) &amp; (~srs_selected_rows_mask)] -= 1\n\n            # apply the rule\n            if rule.flag == _PHON_FLAG_START:\n                srs_out.update(\n                    srs.loc[srs_selected_rows_mask].str.replace(f\"^{rule.pattern}\", rule.replacement, n=1, regex=True)\n                )\n            elif rule.flag == _PHON_FLAG_END:\n                srs_out.update(\n                    srs.loc[srs_selected_rows_mask].str.replace(f\"{rule.pattern}$\", rule.replacement, n=1, regex=True)\n                )\n            elif rule.flag == _PHON_FLAG_MIDDLE:\n                srs_out.update(\n                    srs.loc[srs_selected_rows_mask].str.replace(\n                        f\"^(.+)(?:{rule.pattern})(.+)$\",\n                        f\"\\\\g&lt;1&gt;{rule.replacement}\\\\g&lt;2&gt;\",\n                        n=1,\n                        regex=True,\n                    )\n                )\n            else:\n                raise _new_unknown_flag_error(rule.flag)\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_regex_replacement_table","title":"<code>with_regex_replacement_table(data_source, pattern_column='pattern', flags_column=None, encoding='utf-8', delimiter=',', rng=None)</code>","text":"<p>Mutate series by performing regex-based substitutions sourced from a table. This table must contain a column with the regex patterns to look for and columns for each capture group to look up substitutions. When using regular capture groups, the columns must be numbered starting with 1. When using named capture groups, the columns must be named after the capture groups they are supposed to substitute.</p> <p>Parameters:</p> Name Type Description Default <code>data_source</code> <code>Union[PathLike, str, DataFrame]</code> <p>path to CSV file or data frame containing regex-based substitutions</p> required <code>pattern_column</code> <code>str</code> <p>name of regex pattern column</p> <code>'pattern'</code> <code>flags_column</code> <code>Optional[str]</code> <p>name of regex flag column</p> <code>None</code> <code>encoding</code> <code>str</code> <p>character encoding of the CSV file</p> <code>'utf-8'</code> <code>delimiter</code> <code>str</code> <p>column delimiter of the CSV file</p> <code>','</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by performing regex-based substitutions</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_regex_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    pattern_column: str = \"pattern\",\n    flags_column: _t.Optional[str] = None,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by performing regex-based substitutions sourced from a table.\n    This table must contain a column with the regex patterns to look for and columns for each capture group to look up\n    substitutions.\n    When using regular capture groups, the columns must be numbered starting with 1.\n    When using named capture groups, the columns must be named after the capture groups they are supposed to substitute.\n\n    Args:\n        data_source: path to CSV file or data frame containing regex-based substitutions\n        pattern_column: name of regex pattern column\n        flags_column: name of regex flag column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by performing regex-based substitutions\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    if isinstance(data_source, pd.DataFrame):\n        df = data_source\n    else:\n        df = pd.read_csv(\n            data_source,\n            encoding=encoding,\n            keep_default_na=False,\n            sep=delimiter,\n            dtype=str,\n        )\n\n    if pattern_column not in df.columns:\n        raise ValueError(f\"CSV file at `{data_source}` doesn't have a pattern column\")\n\n    regexes: list[re.Pattern] = []\n    regex_repl_fns: list[_t.Callable[[re.Match], str]] = []\n\n    for _, row in df.iterrows():\n        regex = re.compile(\n            row[pattern_column],\n            0 if flags_column is None else _parse_regex_flags(row[flags_column]),\n        )\n\n        for group_name in regex.groupindex.keys():\n            if group_name not in df.columns:\n                raise ValueError(\n                    f\"regex pattern `{regex}` contains named group `{group_name}` which is \"\n                    f\"not present as a column in the CSV file\"\n                )\n\n        regexes.append(regex)\n        regex_repl_fns.append(_new_regex_replacement_fn(row))\n\n    regex_count = len(regexes)\n\n    if regex_count == 0:\n        raise ValueError(\"must provide at least one regex pattern\")\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        # copy series\n        srs_out = srs.copy(deep=True)\n        # create index df\n        df_idx = _dfbitlookup.with_capacity(len(srs), regex_count, index=srs.index)\n\n        # pandas will warn if str.contains is used with regexes that have capture groups. this is very much\n        # intended and the warning can therefore be ignored.\n        if sys.version_info &gt;= (3, 11):\n            warning_cm = warnings.catch_warnings(category=UserWarning, record=True, action=\"ignore\")\n        else:\n            # in python 3.10 and before, the category and ignore args are not present.\n            warning_cm = warnings.catch_warnings(record=True)\n\n        with warning_cm:\n            # track which regexes match each row\n            for rgx_idx, rgx in enumerate(regexes):\n                _dfbitlookup.set_index(df_idx, srs.str.contains(rgx, regex=True), rgx_idx)\n\n        # check rows that can be mutated\n        srs_rows_to_mutate = _dfbitlookup.any_set(df_idx)\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        # warn if p cannot be met\n        if p_actual &lt; p:\n            _warn_p(with_regex_replacement_table.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # perform selection\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; min(1.0, p / p_actual)\n\n        arr_set_indices = _dfbitlookup.count_bits_per_index(df_idx, regex_count)\n        # keep only indices that have at least one match\n        arr_set_indices = list(filter(lambda tpl: tpl[1] != 0, arr_set_indices))\n        # sort in descending order of frequency\n        arr_set_indices.sort(key=lambda tpl: -tpl[1])\n        # keep only the indices\n        arr_rgx_idx = np.array([tpl[0] for tpl in arr_set_indices])\n\n        # get amount of set bits per row\n        srs_set_bit_count_per_row = _dfbitlookup.count_bits_per_row(df_idx, regex_count).astype(float)\n        # check which rows are not zero to avoid div by 0\n        srs_count_not_zero = srs_set_bit_count_per_row != 0\n\n        for rgx_idx in arr_rgx_idx:\n            # draw random values\n            arr_rng_vals = rng.random(size=len(srs))\n\n            # determine the likelihood of each row for being chosen in this iteration\n            srs_rng_prob = srs_set_bit_count_per_row.copy(deep=True)\n            srs_rng_prob[srs_count_not_zero] = 1.0 / srs_rng_prob[srs_count_not_zero]\n\n            # check which rows are affected by this regex\n            srs_selected_rows_mask = (\n                srs_rows_to_mutate  # select eligible rows\n                &amp; (srs == srs_out)  # AND select rows that haven't been mutated yet\n                &amp; _dfbitlookup.test_index(df_idx, rgx_idx)  # AND select rows that match this regex\n                &amp; (arr_rng_vals &lt; srs_rng_prob)  # AND select rows that are randomly selected\n            )\n\n            # increase chance of being picked for rows that match this rule and that\n            # have NOT been selected by chance this time\n            srs_set_bit_count_per_row[_dfbitlookup.test_index(df_idx, rgx_idx) &amp; (~srs_selected_rows_mask)] -= 1\n\n            # apply the regex\n            srs_out.update(\n                srs.loc[srs_selected_rows_mask].str.replace(regexes[rgx_idx], regex_repl_fns[rgx_idx], regex=True)\n            )\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_repeat","title":"<code>with_repeat(join_with=' ', rng=None)</code>","text":"<p>Mutate series by repeating its contents. By default, selected entries will be duplicated and separated by a whitespace.</p> <p>Parameters:</p> Name Type Description Default <code>join_with</code> <code>str</code> <p>joining character to use, space by default</p> <code>' '</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by repeating its contents</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_repeat(join_with: str = \" \", rng: _t.Optional[np.random.Generator] = None) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by repeating its contents.\n    By default, selected entries will be duplicated and separated by a whitespace.\n\n    Args:\n        join_with: joining character to use, space by default\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by repeating its contents\n    \"\"\"\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n        srs_rows_to_mutate = pd.Series(rng.random(size=len(srs)) &lt; p, index=srs.index)\n        srs_out.update(srs_out.loc[srs_rows_to_mutate] + join_with + srs_out.loc[srs_rows_to_mutate])\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_replacement_table","title":"<code>with_replacement_table(data_source, source_column=0, target_column=1, inline=False, reverse=False, encoding='utf-8', delimiter=',', rng=None)</code>","text":"<p>Mutate series by randomly substituting character sequences from a replacement table. The table must have at least two columns: a source and a target value column. A source value may have multiple target values that it can map to. Strings that do not contain any possible source values are not mutated. It is possible for a string to not be modified if no target value could be picked for its assigned source value. This can only happen if a source value is mapped to multiple target values. In this case, each target value will be independently selected or not. If the source and target column are provided as strings, and a path to a CSV file is provided to this function, then it is automatically assumed that the CSV file has a header row. The mutator will favor less common replacements over more common ones.</p> <p>Parameters:</p> Name Type Description Default <code>data_source</code> <code>Union[PathLike, str, DataFrame]</code> <p>path to CSV file or data frame containing replacement table</p> required <code>source_column</code> <code>Union[str, int]</code> <p>name or index of the source column</p> <code>0</code> <code>target_column</code> <code>Union[str, int]</code> <p>name or index of the target column</p> <code>1</code> <code>inline</code> <code>bool</code> <p>whether to perform replacements inline</p> <code>False</code> <code>reverse</code> <code>bool</code> <p>whether to allow replacements from target to source column</p> <code>False</code> <code>encoding</code> <code>str</code> <p>character encoding of the CSV file</p> <code>'utf-8'</code> <code>delimiter</code> <code>str</code> <p>column delimiter of the CSV file</p> <code>','</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series according to a replacement table</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_replacement_table(\n    data_source: _t.Union[PathLike, str, pd.DataFrame],\n    source_column: _t.Union[str, int] = 0,\n    target_column: _t.Union[str, int] = 1,\n    inline: bool = False,\n    reverse: bool = False,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\",\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly substituting character sequences from a replacement table.\n    The table must have at least two columns: a source and a target value column.\n    A source value may have multiple target values that it can map to.\n    Strings that do not contain any possible source values are not mutated.\n    It is possible for a string to not be modified if no target value could be picked for its assigned source value.\n    This can only happen if a source value is mapped to multiple target values.\n    In this case, each target value will be independently selected or not.\n    If the source and target column are provided as strings, and a path to a CSV file is provided\n    to this function, then it is automatically assumed that the CSV file has a header row.\n    The mutator will favor less common replacements over more common ones.\n\n    Args:\n        data_source: path to CSV file or data frame containing replacement table\n        source_column: name or index of the source column\n        target_column: name or index of the target column\n        inline: whether to perform replacements inline\n        reverse: whether to allow replacements from target to source column\n        encoding: character encoding of the CSV file\n        delimiter: column delimiter of the CSV file\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series according to a replacement table\n    \"\"\"\n\n    if rng is None:\n        rng = np.random.default_rng()\n\n    if type(source_column) is not type(target_column):\n        raise ValueError(\"source and target columns must be of the same type\")\n\n    # skip check for source_column bc they are both of the same type already\n    if not isinstance(target_column, str) and not isinstance(target_column, int):\n        raise ValueError(\"source and target columns must be either a string or an integer\")\n\n    if isinstance(data_source, pd.DataFrame):\n        df = data_source\n    else:\n        header = isinstance(target_column, str)\n\n        df = pd.read_csv(\n            data_source,\n            header=0 if header else None,\n            dtype=str,\n            usecols=[source_column, target_column],\n            keep_default_na=False,\n            sep=delimiter,\n            encoding=encoding,\n        )\n\n    if reverse:\n        # flip columns and concat\n        df = pd.concat(\n            [\n                df,\n                pd.DataFrame(\n                    data={\n                        source_column: df.loc[:, target_column],\n                        target_column: df.loc[:, source_column],\n                    }\n                ),\n            ],\n            ignore_index=True,\n        )\n\n    # unique() returns a ndarray\n    arr_unique_source_values = df.loc[:, source_column].unique()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        # create copy\n        srs_out = srs.copy(deep=True)\n        # create index df\n        df_idx = _dfbitlookup.with_capacity(len(srs), len(arr_unique_source_values), index=srs.index)\n\n        for src_idx, source in enumerate(arr_unique_source_values):\n            if inline:\n                _dfbitlookup.set_index(df_idx, srs.str.contains(source), src_idx)\n            else:\n                _dfbitlookup.set_index(df_idx, srs == source, src_idx)\n\n        # check rows that can be mutated\n        srs_rows_to_mutate = _dfbitlookup.any_set(df_idx)\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        # warn if p cannot be met\n        if p_actual &lt; p:\n            _warn_p(with_replacement_table.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # perform actual selection\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        arr_set_indices = _dfbitlookup.count_bits_per_index(df_idx, len(arr_unique_source_values))\n        # keep only indices that have at least one match\n        arr_set_indices = list(filter(lambda tpl: tpl[1] != 0, arr_set_indices))\n        # sort in ascending order of frequency\n        arr_set_indices.sort(key=lambda tpl: tpl[1])\n        # keep only the indices\n        arr_src_idx = np.array([tpl[0] for tpl in arr_set_indices])\n\n        # iterate over source values\n        for src_idx in arr_src_idx:\n            # retrieve the assigned source value\n            src_value = arr_unique_source_values[src_idx]\n            # check which rows will have this source value replaced\n            srs_src_selected = (\n                srs_rows_to_mutate  # select rows that are eligible for mutation\n                &amp; (srs == srs_out)  # AND that have not been mutated yet\n                &amp; _dfbitlookup.test_index(df_idx, src_idx)  # AND that contain this source value\n            )\n\n            # randomize target values\n            arr_target_values = df.loc[df[source_column] == src_value, target_column].array\n            arr_target_values_selected = rng.choice(arr_target_values, size=srs_src_selected.sum())\n\n            # perform replacements\n            for target_value in np.unique(arr_target_values_selected):\n                srs_out.update(\n                    srs.loc[srs_src_selected]\n                    .loc[arr_target_values_selected == target_value]\n                    .str.replace(src_value, target_value, n=1, regex=False)\n                )\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_substitute","title":"<code>with_substitute(charset=string.ascii_letters, rng=None)</code>","text":"<p>Mutate data by replacing single characters with a new one. The characters are drawn from the provided charset.</p> Notes <p>It is possible for a character to be replaced by itself.</p> <p>Parameters:</p> Name Type Description Default <code>charset</code> <code>Union[str, list[str]]</code> <p>character string or list of characters to sample from</p> <code>ascii_letters</code> <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by substituting random characters</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_substitute(\n    charset: _t.Union[str, list[str]] = string.ascii_letters,\n    rng: _t.Optional[np.random.Generator] = None,\n) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate data by replacing single characters with a new one.\n    The characters are drawn from the provided charset.\n\n    Notes:\n        It is possible for a character to be replaced by itself.\n\n    Args:\n        charset: character string or list of characters to sample from\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by substituting random characters\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    if isinstance(charset, str):\n        charset = list(charset)\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n\n        # limit to strings that have at least a single character\n        srs_rows_to_mutate = srs.str.len() &gt;= 1\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        if p_actual &lt; p:\n            _warn_p(with_substitute.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # select subset of rows to mutate\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        # count rows that will be mutated\n        rows_to_mutate_count = srs_rows_to_mutate.sum()\n\n        # generate random indices\n        arr_rng_vals = rng.random(size=rows_to_mutate_count)\n        arr_rng_idx = np.floor(srs.loc[srs_rows_to_mutate].str.len() * arr_rng_vals).astype(int)\n\n        # generate random characters to insert\n        arr_rng_chars = rng.choice(charset, size=rows_to_mutate_count)\n\n        for idx in arr_rng_idx.unique():\n            arr_this_idx = arr_rng_idx == idx\n            srs_this_idx = srs.loc[srs_rows_to_mutate].loc[arr_this_idx]\n            srs_out.update(srs_this_idx.str[:idx] + arr_rng_chars[arr_this_idx] + srs_this_idx.str[idx + 1 :])\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_transpose","title":"<code>with_transpose(rng=None)</code>","text":"<p>Mutate series by randomly swapping neighboring characters.</p> Notes <p>It is possible for the same two neighboring characters to be swapped.</p> <p>Parameters:</p> Name Type Description Default <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by swapping adjacent characters</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_transpose(rng: _t.Optional[np.random.Generator] = None) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by randomly swapping neighboring characters.\n\n    Notes:\n        It is possible for the same two neighboring characters to be swapped.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by swapping adjacent characters\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n\n        # limit to strings that have at least two characters\n        srs_rows_to_mutate = srs.str.len() &gt;= 2\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        if p_actual &lt; p:\n            _warn_p(with_transpose.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # select subset of rows to mutate\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        # count rows that will be mutated\n        rows_to_mutate_count = srs_rows_to_mutate.sum()\n\n        # generate random indices to transpose characters at\n        arr_rng_vals = rng.random(size=rows_to_mutate_count)\n        arr_rng_idx = np.floor(\n            (srs.loc[srs_rows_to_mutate].str.len() - 1) * arr_rng_vals  # -1 to account for neighboring chars\n        ).astype(int)\n\n        for idx in arr_rng_idx.unique():\n            srs_this_idx = srs.loc[srs_rows_to_mutate].loc[arr_rng_idx == idx]\n            srs_out.update(\n                srs_this_idx.str[:idx] + srs_this_idx.str[idx + 1] + srs_this_idx.str[idx] + srs_this_idx.str[idx + 2 :]\n            )\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"api-reference/#gecko.mutator.with_uppercase","title":"<code>with_uppercase(rng=None)</code>","text":"<p>Mutate series by converting its contents to uppercase.</p> <p>Parameters:</p> Name Type Description Default <code>rng</code> <code>Optional[Generator]</code> <p>random number generator to use</p> <code>None</code> <p>Returns:</p> Type Description <code>Mutator</code> <p>function that mutates series by converting its contents to uppercase</p> Source code in <code>gecko/mutator.py</code> <pre><code>def with_uppercase(rng: _t.Optional[np.random.Generator] = None) -&gt; _gt.Mutator:\n    \"\"\"\n    Mutate series by converting its contents to uppercase.\n\n    Args:\n        rng: random number generator to use\n\n    Returns:\n        function that mutates series by converting its contents to uppercase\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _mutate_series(srs: pd.Series, p: float) -&gt; pd.Series:\n        srs_out = srs.copy(deep=True)\n\n        # limit series to strings that are not all uppercase yet\n        srs_rows_to_mutate = ~srs.str.isupper()\n        possible_rows_to_mutate = srs_rows_to_mutate.sum()\n        p_actual = possible_rows_to_mutate / len(srs)\n\n        if p_actual &lt; p:\n            _warn_p(with_uppercase.__name__, p, p_actual)\n\n        if possible_rows_to_mutate == 0:\n            return srs_out\n\n        # select subset of rows to mutate\n        p_subset_select = min(1.0, p / p_actual)\n        arr_rng_vals = rng.random(size=possible_rows_to_mutate)\n        srs_rows_to_mutate.loc[srs_rows_to_mutate] = arr_rng_vals &lt; p_subset_select\n\n        # update selected rows\n        srs_out.update(srs.loc[srs_rows_to_mutate].str.upper())\n\n        return srs_out\n\n    def _mutate(srs_lst: list[pd.Series], p: float = 1.0) -&gt; list[pd.Series]:\n        _check_probability_in_bounds(p)\n        return [_mutate_series(srs, p) for srs in srs_lst]\n\n    return _mutate\n</code></pre>"},{"location":"citing-gecko/","title":"Citing Gecko","text":"<p>If you find Gecko useful, and you wish to publish your work or research based on it, then we would love to see you properly cite Gecko.  This page is intended to point you to all our published research to date and to help you correctly cite it.</p>"},{"location":"citing-gecko/#publications","title":"Publications","text":""},{"location":"citing-gecko/#softwarex-aug-10-2024","title":"SoftwareX (Aug 10, 2024)","text":"<ul> <li>Article: Gecko: A Python library for the generation and mutation of realistic personal identification data at scale</li> <li>DOI: 10.1016/j.softx.2024.101846</li> </ul> Abstract <p>Record linkage algorithms require testing on realistic personal identification data to assess their efficacy in real-world settings. Access to this kind of data is often infeasible due to rigid data privacy regulations. Open-source tools for generating realistic data are either unmaintained or lack performance to scale to the generation of millions of records. We introduce Gecko as a Python library for creating shareable scripts to generate and mutate realistic personal data. Built on top of popular data science libraries in Python, it greatly facilitates integration into existing workflows. Benchmarks are provided to prove the library\u2019s performance and scalability claims.</p> APAIEEEISO 690MLABibTeX <p>Jugl, M., &amp; Kirsten, T. (2024). Gecko: A Python library for the generation and mutation of realistic personal identification data at scale. SoftwareX, 27, 101846. https://doi.org/10.1016/j.softx.2024.101846</p> <p>M. Jugl and T. Kirsten, \u201cGecko: A Python library for the generation and mutation of realistic personal identification data at scale,\u201d SoftwareX, vol. 27, p. 101846, Sep. 2024, doi: 10.1016/j.softx.2024.101846.</p> <p>JUGL, Maximilian and KIRSTEN, Toralf, 2024. Gecko: A Python library for the generation and mutation of realistic personal identification data at scale. SoftwareX. Vol. 27, p. 101846. DOI 10.1016/j.softx.2024.101846. </p> <p>Jugl, Maximilian, and Toralf Kirsten. \u201cGecko: A Python Library for the Generation and Mutation of Realistic Personal Identification Data at Scale.\u201d SoftwareX, vol. 27, Sept. 2024, p. 101846. DOI.org (Crossref), https://doi.org/10.1016/j.softx.2024.101846.</p> <pre><code>@article{jugl_gecko_2024,\n    title = {Gecko: {A} {Python} library for the generation and mutation of realistic personal identification data at scale},\n    volume = {27},\n    issn = {2352-7110},\n    shorttitle = {Gecko},\n    url = {https://www.sciencedirect.com/science/article/pii/S2352711024002176},\n    doi = {10.1016/j.softx.2024.101846},\n    abstract = {Record linkage algorithms require testing on realistic personal identification data to assess their efficacy in real-world settings. Access to this kind of data is often infeasible due to rigid data privacy regulations. Open-source tools for generating realistic data are either unmaintained or lack performance to scale to the generation of millions of records. We introduce Gecko as a Python library for creating shareable scripts to generate and mutate realistic personal data. Built on top of popular data science libraries in Python, it greatly facilitates integration into existing workflows. Benchmarks are provided to prove the library\u2019s performance and scalability claims.},\n    urldate = {2024-10-17},\n    journal = {SoftwareX},\n    author = {Jugl, Maximilian and Kirsten, Toralf},\n    month = sep,\n    year = {2024},\n    keywords = {Data privacy, Record linkage, Python, Data science},\n    pages = {101846},\n}\n</code></pre>"},{"location":"citing-gecko/#presentations","title":"Presentations","text":""},{"location":"citing-gecko/#18th-leipzig-research-festival-for-life-sciences-jan-30-2025","title":"18th Leipzig Research Festival for Life Sciences (Jan 30, 2025)","text":"<ul> <li>Abstract: Improving record linkage quality on identification data in the Leipzig Obesity BioBank</li> <li>DOI: to be released</li> <li>Slides: Download (PDF)</li> </ul> Abstract <p>Within longitudinal medical studies, identification data (IDAT) is collected from participants which enables them to be reidentified across multiple sessions. Trusted third parties may then consolidate medical records obtained from the same person before handing them off to data scientists to conduct their research. This process of merging records using stable or quasi-identifiers is referred to as \u201crecord linkage\u201d. Due to the nature of these studies, errors arise in the collected data due to changing data entry methods and staff over time. Determining the required level of similarity to classify a record pair as a match therefore becomes a reoccurring challenge in the field of record linkage. </p> <p>We present a method for estimating similarity thresholds for privacy-preserving record linkage (PPRL) using IDAT from two sub-studies of the Leipzig Obesity BioBank (LOBB). LOBB collects samples from over 8000 patients to conduct research on diseases related to obesity. We analyze the types and frequencies of typographical errors present in their IDAT. This information is used to infer a configuration for Gecko, which is a software library used to generate a set of realistic personal IDAT that closely replicates the errors found in the LOBB data. We then evaluate the impact of each error class on match quality using these datasets. Our findings provide needed insights into the challenges of integrating real-world IDAT, which is necessary in PPRL where access to such data is often prohibited, and underline its significance in enhancing research validity and reliability. </p>"},{"location":"citing-gecko/#69th-annual-gmds-conference-sep-9-2024","title":"69th Annual GMDS Conference (Sep 9, 2024)","text":"<ul> <li>Abstract: Generation and mutation of realistic personal identification data for the evaluation of record linkage algorithms</li> <li>DOI: 10.3205/24gmds020</li> <li>Slides: Download (PDF)</li> </ul> Abstract <p>Personal data is often scattered across various stakeholders due to its collection for various data collection purposes. This leads to a high degree of fragmentation, which necessitates the consolidation of multiple data sources in order to obtain a complete view of natural persons. Linking personal data records together is trivial with a globally unique personal identifier, but such an identifier is often either not available or out of scope in most scenarios. Algorithms from the field of record linkage have therefore been employed instead. They operate on identification data and assign a similarity to record pairs in order to decide whether they should be merged or not.</p> <p>These record linkage algorithms require testing on realistic data to evaluate their efficacy in real-world situations. However due to the sensitive nature of identification data, access to real-world testing data has been mostly exclusive to researchers with personal ties to medical institutions in the past. This has led to the creation of tools which generate personal data that seems realistic based on publicly available data sources. To the best of our knowledge, all previously published tools are either inactive, unmaintained, closed source or outdated.</p> <p>We present Gecko: an open-source Python library for the generation and mutation of personal identification data based on public data and error sources. It takes after GeCo which showed the promise of creating reproducible and shareable scripts to generate data. The ease of integration into data science applications of the original library leaves a lot to be desired. Gecko addresses this by reimplementing GeCo\u2019s core features on top of popular data science libraries and extending them by fixing GeCo\u2019s limitations, allowing the generation of arbitrarily complex multivariate data, fine-grain control over its randomized routines and data mutation across multiple instead of single fields.</p> <p>Gecko makes extensive use of Pandas data frames which allow exports of generated data in various interoperable file formats such as CSV. We validated that data generated by Gecko can be imported into E-PIX, which ensures Gecko\u2019s compatibility with other tools with CSV parsing capabilities. Furthermore, we extensively benchmarked Gecko to ensure that it fulfills its performance claims. Despite the lack of test data from other solutions in the field, we estimate that Gecko\u2019s single-core performance stands as best-in-class by a comfortable margin.</p> <p>Gecko\u2019s performance and configurability allows it to generate datasets with millions of records for the validation of record linkage algorithms in reasonable time frames. Its capabilities to quickly generate data on-the-fly opens it up for use in other data science applications where realistic identification data may be needed. A publicly available data repository allows for quick testing of Gecko\u2019s capabilities for library users. We encourage users of Gecko to donate data samples from various regions and languages in order to obtain higher multilingual coverage. Future versions of Gecko aim at providing export facilities for FHIR, as well as support for more complex error classes such as temporal errors and column shifts in data.</p>"},{"location":"citing-gecko/#8th-freiberg-phd-conference-jun-7-2024","title":"8th Freiberg PhD Conference (Jun 7, 2024)","text":"<ul> <li>Abstract: Gecko: generation and mutation of realistic identification data at scale for record linkage evaluation</li> <li>URN: urn:nbn:de:bsz:105-qucosa2-926058</li> <li>Slides: Download (PDF)</li> </ul> Abstract <p>Collection of personal data at different stakeholders for various purposes leads to fragmentation. Consolidation of these data sources is therefore necessary to get a complete view. In the absence of a globally unique personal identifier, record linkage algorithms are being used instead. These algorithms require testing on realistic data which, due to their sensitive nature, led to the development of data generation tools.</p> <p>We present Gecko: an open-source Python library for the generation and mutation of personal identification data at scale. Inspired by its predecessor GeCo, it provides its users with a set of functions to enable the creation of shareable and reproducible scripts for data generation. It comes with a simplified API and substantial performance gains due to the usage of popular scientific computing libraries under the hood. Aside from the validation of record linkage algorithms, its performance enables the integration into a variety of data science applications.</p>"},{"location":"data-generation/","title":"Generating data","text":"<p>A generator is a function that takes in a number of records and returns a list of Pandas series where each series represents a data column. For example, a generator that returns a single column containing numbers from one up to the desired amount of records could look like this.</p> <pre><code>import pandas as pd\n\n\ndef generate_numbers(count: int) -&gt; list[pd.Series]:\n    numbers = [i + 1 for i in range(count)]\n    return [pd.Series(numbers)]\n</code></pre> <p>Gecko comes with a bunch of built-in generators which are described on this page. They are exposed in Gecko's <code>generator</code> module.</p>"},{"location":"data-generation/#available-generators","title":"Available generators","text":""},{"location":"data-generation/#frequency-tables","title":"Frequency tables","text":"<p>One of the most common sources to generate realistic-looking data are frequency tables. Gecko supports loading frequency tables from CSV files and generating data based off frequencies listed within.</p> <p>Assume a CSV file containing a list of fruits and their frequencies. The goal is to generate a series that has a similar distribution of values.</p> CSVTable <pre><code>fruit,count\napple,100\nbanana,50\norange,80\n</code></pre> Fruit Count Apple 100 Banana 50 Orange 80 <p>Gecko exposes the function <code>from_frequency_table</code> for this purpose. Point the generator to the CSV file. Since the columns are named, the value and frequency columns need to be explicitly passed in.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\nrng = np.random.default_rng(112358)\nfruit_generator = generator.from_frequency_table(\n    \"fruit.csv\",\n    value_column=\"fruit\",\n    freq_column=\"count\",\n    rng=rng\n)\n\nprint(fruit_generator(1000))\n# =&gt; [[\"orange\", \"apple\", \"apple\", \"banana\", ..., \"apple\", \"apple\"]]\n</code></pre>"},{"location":"data-generation/#multi-column-frequency-tables","title":"Multi-column frequency tables","text":"<p>Oftentimes, frequencies do not depend on a single variable. For this purpose, Gecko can generate values based off of multiple columns within a CSV file.</p> <p>Continuing the example from above, assume a frequency table with fruits and their types.</p> CSVTable <pre><code>fruit,type,count\napple,braeburn,30\napple,elstar,70\nbanana,cavendish,40\nbanana,plantain,10\norange,clementine,55\norange,mandarin,25\n</code></pre> Fruit Type Count Apple Braeburn 30 Apple Elstar 70 Banana Cavendish 40 Banana Plantain 10 Orange Clementine 55 Orange Mandarin 25 <p>These types of frequency tables are handled by the <code>from_multicolumn_frequency_table</code> function. The syntax is similar to that of <code>from_frequency_table</code>, except multiple value columns can be passed into it. This results in a list of series: one for each value column passed into the generator.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\nrng = np.random.default_rng(14916)\nfruit_generator = generator.from_multicolumn_frequency_table(\n    \"./fruit-types.csv\",\n    value_columns=[\"fruit\", \"type\"],\n    freq_column=\"count\",\n    rng=rng,\n)\n\nprint(fruit_generator(1000))\n# =&gt; [[\"banana\", \"orange\", \"apple\", \"orange\", ..., \"orange\", \"banana\"],\n#     [\"cavendish\", \"mandarin\", \"elstar\", \"clementine\", ..., \"mandarin\", \"cavendish\"]]\n</code></pre>"},{"location":"data-generation/#numeric-distributions","title":"Numeric distributions","text":"<p>Gecko provides functions to sample random numbers from uniform and normal distributions. These are exposed using the <code>from_uniform_distribution</code> and <code>from_normal_distribution</code> functions. The numbers are formatted into strings, where the amount of decimal places can be passed to the generators.</p> <p>The generator for uniform distributions requires an inclusive lower bound and an exclusive upper bound.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\nrng = np.random.default_rng(2357)\nuniform_generator = generator.from_uniform_distribution(\n    low=40, high=80, precision=2, rng=rng\n)\n\nprint(uniform_generator(100))\n# =&gt; [[47.71, 77.53, 54.93, 50.04, ..., 51.69, 65.63]]\n</code></pre> <p>The generator for normal distributions requires a mean and a standard deviation.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\nrng = np.random.default_rng(3731)\nnormal_generator = generator.from_normal_distribution(\n    mean=22, sd=3, precision=2, rng=rng\n)\n\nprint(normal_generator(100))\n# =&gt; [[23.77, 17.13, 22.08, 22.07, ..., 21.10, 22.67]]\n</code></pre>"},{"location":"data-generation/#date-and-time-information","title":"Date and time information","text":"<p>One of the most commonly collected pieces of identifying information are dates of birth. More technical sources of dates and times are record creation and update timestamps, as well as other applications of  tracing data entry.</p> <p>Gecko provides <code>from_datetime_range</code> to generate random timestamps from a uniform distribution. It can utilize any of Python's built-in format codes for datetime objects to output them to text.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\n\nrng = np.random.default_rng(0xcafebabe)\ndatetime_generator = generator.from_datetime_range(\n    start_dt=\"1920-01-01\", \n    end_dt=\"2020-01-01\", \n    dt_format=\"%d.%m.%Y\", \n    unit=\"D\", \n    rng=rng\n)\n\nprint(datetime_generator(100))\n# =&gt; [[\"05.05.1967\", \"07.06.1923\", ..., \"09.12.1986\", \"11.11.1943\"]]\n</code></pre> <p>The \"resolution\" of the generated strings can be defined by setting the smallest unit of time to alter. Gecko can generate unique strings down to days (<code>D</code>), hours (<code>h</code>), minutes (<code>m</code>) and seconds (<code>s</code>) respectively. Months are years are currently unsupported since the underlying timespans are nonlinear.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\n\nrng = np.random.default_rng(0xdeadbeef)\ndatetime_generator = generator.from_datetime_range(\n    start_dt=\"1920-01-01\", \n    end_dt=\"2020-01-01\", \n    dt_format=\"%d.%m.%Y %H:%M:%S\", \n    unit=\"m\", \n    rng=rng\n)\n\nprint(datetime_generator(100))\n# =&gt; [[\"26.02.1933 17:57:00\", \"17.12.1954 03:01:00\", ..., \"15.02.1950 01:29:00\", \"24.06.1922 23:46:00\"]]\n</code></pre>"},{"location":"data-generation/#grouped-generators","title":"Grouped generators","text":"<p>Multiple generators can be grouped into one single generator using <code>with_group</code>. For instance, this could be used for generating data collected from several data sources that cannot be modeled using  any of the other generators.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\nrng = np.random.default_rng(1234)\n\ndt_format = \"%d.%m.%Y\"\ndt_source_1_gen = generator.from_datetime_range(\n    start_dt=\"1920-01-01\",\n    end_dt=\"1960-01-01\",\n    dt_format=dt_format,\n    unit=\"D\",\n    rng=rng\n)\ndt_source_2_gen = generator.from_datetime_range(\n    start_dt=\"1980-01-01\",\n    end_dt=\"2010-01-01\",\n    dt_format=dt_format,\n    unit=\"D\",\n    rng=rng\n)\n\ngroup_gen = generator.from_group([\n    (.6, dt_source_1_gen),\n    (.4, dt_source_2_gen),\n], rng=rng)\n\nprint(group_gen(100))\n# =&gt; [[\"20.10.1986\", \"13.12.1941\", ..., \"25.05.1946\"]]\n</code></pre>"},{"location":"data-generation/#custom-generators","title":"Custom generators","text":"<p>Any function that returns a string can be converted into a generator. Gecko provides <code>from_function</code> as a wrapper around such functions.</p> <p>Warning</p> <p>You should not use <code>from_function</code> if performance matters. All built-in generators provided by Gecko are optimized to generate many values at once. With <code>from_function</code>, new values are generated one by one.</p> <p>Arguments taken by the wrapped function must be passed to <code>from_function</code>. These arguments are then passed on when values are being generated. Take the following snippet for example, which generates a random sequence of letters.</p> <pre><code>import numpy as np\nimport string\n\nfrom gecko import generator\n\n\ndef next_letter(\n        my_rng: np.random.Generator,\n        charset: str = string.ascii_lowercase\n):\n    return my_rng.choice(list(charset))\n\n\nrng = np.random.default_rng(11247)\n\nmy_generator = generator.from_function(\n    next_letter,\n    my_rng=rng\n)\nprint(my_generator(100))\n# =&gt; [[\"e\", \"m\", \"e\", \"y\", ..., \"u\", \"h\"]]\n\nmy_umlaut_generator = generator.from_function(\n    next_letter,\n    my_rng=rng,\n    charset=\"\u00e4\u00f6\u00fc\"\n)\nprint(my_umlaut_generator(100))\n# =&gt; [[\"\u00fc\", \"\u00fc\", \"\u00fc\", \"\u00e4\", ..., \"\u00e4\", \"\u00e4\"]]\n</code></pre> <p>An interesting use case is to use Gecko in combination with the popular Faker library. Faker offers many providers for generating synthetic data. All providers that return strings can be plugged seamlessly into Geckos <code>from_function</code> generator. However, users of Faker are responsible for seeding their own RNG instances to achieve reproducible results.</p> <pre><code>from faker import Faker\nfrom gecko import generator\n\nfake = Faker(\"de_DE\")\nfake.seed_instance(13579)\n\nfirst_name_generator = generator.from_function(fake.first_name)\nage_generator = generator.from_function(\n    fake.date_of_birth,\n    minimum_age=18,\n    maximum_age=80,\n)\n\nprint(first_name_generator(100))\n# =&gt; [[\"Jurij\", \"Andy\", \"Gundolf\", \"Gordana\", ..., \"Ismet\", \"Annegrete\"]]\nprint(age_generator(100))\n# =&gt; [[\"1969-09-12\", \"1971-12-15\", \"1985-03-10\", \"1949-06-18\", ..., \"1956-07-26\", \"1964-09-26\"]]\n</code></pre>"},{"location":"data-generation/#multiple-generators","title":"Multiple generators","text":"<p>All generators return one or more series, so it is reasonable to combine them all together into one Pandas data frame for further processing. Gecko provides the <code>to_dataframe</code> function which takes in a list of generators and column names and generates a data frame based on them. The following example utilizes most of the generators shown in this guide.</p> <pre><code>import numpy as np\n\nfrom gecko import generator\n\nrng = np.random.default_rng(222)\n\nfruit_generator = generator.from_multicolumn_frequency_table(\n    \"./fruit-types.csv\",\n    value_columns=[\"fruit\", \"type\"],\n    freq_column=\"count\",\n    rng=rng,\n)\n\nweight_generator = generator.from_normal_distribution(\n    mean=150,\n    sd=50,\n    precision=1,\n    rng=rng,\n)\n\namount_generator = generator.from_uniform_distribution(\n    2,\n    8,\n    precision=0,\n    rng=rng,\n)\n\n\ndef next_fruit_grade(rand: np.random.Generator) -&gt; str:\n    return rand.choice(list(\"ABC\"))\n\n\ngrade_generator = generator.from_function(\n    next_fruit_grade,\n    rand=rng,\n)\n\ndf = generator.to_data_frame(\n    [\n        ((\"fruit\", \"type\"), fruit_generator),\n        (\"weight_in_grams\", weight_generator),\n        (\"amount\", amount_generator),\n        (\"grade\", grade_generator),\n    ],\n    1_000,\n)\n\nprint(df)\n# =&gt; [[\"fruit\", \"type\", \"weight_in_grams\", \"amount\", \"grade\"],\n#       [\"apple\", \"elstar\", \"162.5\", \"8\", \"C\"],\n#       [\"orange\", \"clementine\", \"186.8\", \"5\", \"A\"],\n#       ...,\n#       [\"apple\", \"elstar\", \"78.7\", \"4\", \"B\"]]\n</code></pre>"},{"location":"data-mutation/","title":"Mutating data","text":"<p>A mutator is a function that takes in a list of  Pandas series and a probability between zero and one and returns a list of mutated series. The probability dictates which maximum percentage of rows within each series should be mutated.</p> <p>If a mutator fails to meet the requested percentage, most likely due to the contents of a series not being  able to be mutated due to preconditions imposed by the mutator, it will emit a <code>GeckoWarning</code>.</p> <p>Gecko comes with a bunch of built-in mutators which are described on this page. They are exposed in Gecko's <code>mutator</code> module.</p>"},{"location":"data-mutation/#available-mutators","title":"Available mutators","text":""},{"location":"data-mutation/#keyboard-typos","title":"Keyboard typos","text":"<p>One of the most common sources for typos are adjacent keys on a keyboard. Gecko supports loading of keyboard layouts and applying typos based on them. Currently, keyboard layouts must be provided as an XML file from the Unicode CLDR repository. Gecko parses these files and determines all neighboring keys of each key, as well as their variants with and without Shift pressed.</p> <p>Warning</p> <p>As of Unicode CLDR keyboard specification is under a major redesign as of release 44. Support will be added as soon as the specification is finalized. For now, please retrieve CLDR keyboard files from a release tagged 43 or earlier. The examples in this documentation use files from the CLDR release 43.</p> <p>Download the German keyboard layout from the CLDR repository. The corresponding mutator is called <code>with_cldr_keymap_file</code>. Point the mutator to the file you just downloaded. In the following example, one character in each word is substituted by another neighboring character on the German keyboard.</p> <pre><code>import pandas as pd\nimport numpy as np\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(3141)\nkb_mutator = mutator.with_cldr_keymap_file(\n    \"./de-t-k0-windows.xml\",\n    rng=rng\n)\nsrs = pd.Series([\"apple\", \"banana\", \"clementine\"])\nprint(kb_mutator([srs], 1.0))\n# =&gt; [[\"aople\", \"ganana\", \"clementkne\"]]\n</code></pre> <p>By default, this mutator considers all possible neighboring keys for each key. If you want to constrain typos to a certain set of characters, you can pass an optional string of characters or a list of characters to this mutator. One such example is to limit the mutator to digits when manipulating a series of numbers that are broken up by non-digit characters. The following snippet avoids the substitution of hyphens by specifying that only digits may be manipulated.</p> <pre><code>import pandas as pd\nimport numpy as np\nimport string\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(2718)\nkb_mutator = mutator.with_cldr_keymap_file(\n    \"./de-t-k0-windows.xml\",\n    charset=string.digits,\n    rng=rng\n)\nsrs = pd.Series([\"123-456-789\", \"727-727-727\", \"294-753-618\"])\nprint(kb_mutator([srs], 1.0))\n# =&gt; [[\"123-457-789\", \"717-727-727\", \"295-753-618\"]]\n</code></pre>"},{"location":"data-mutation/#phonetic-errors","title":"Phonetic errors","text":"<p>One of the most challenging error sources to model are phonetic errors. These are words that sound the same but are written differently.</p> <p>In German, for example, \"\u00df\" can almost always be replaced with \"ss\" and still have the word that it's in sound the same. Whether one writes \"Stra\u00dfe\" or \"Strasse\" does not matter as far as pronunciation is concerned. The same holds for \"dt\" and \"tt\" at the end of a word, since both reflect a hard \"t\" sound. One can derive rules from similarly sounding character sequences.</p> <p>Gecko offers a method for modelling these rules and introducing phonetic errors based on them. A phonetic rule in Gecko consists of a source pattern (\"\u00df\", \"dt\"), a target pattern (\"ss\", \"tt\") and positional flags. The flags determine whether this rule applies at the start (<code>^</code>), in the middle (<code>_</code>) or the end (<code>$</code>) of a word. These flags can be freely combined. The absence of a positional flag implies that a rule can be applied anywhere in a string. Taking the example from above, a suitable rule table could look like this.</p> CSVTable <pre><code>source,target,flags\n\u00df,ss,\ndt,tt,$\n</code></pre> Source Target Flags \u00df ss dt tt $ <p>Gecko exposes the <code>with_phonetic_replacement_table</code> function to handle these types of tables. The call signature is similar to that of <code>with_replacement_table</code>.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(8844167)\n\nphonetic_mutator = mutator.with_phonetic_replacement_table(\n    \"./phonetic-rules-de.csv\",\n    source_column=\"source\",\n    target_column=\"target\",\n    flags_column=\"flags\",\n    rng=rng,\n)\n\nsrs = pd.Series([\"stra\u00dfe\", \"stadt\", \"schie\u00dfen\"])\nprint(phonetic_mutator([srs], 1.0))\n# =&gt; [[\"strasse\", \"statt\", \"schiessen\"]]\n</code></pre>"},{"location":"data-mutation/#missing-values","title":"Missing values","text":"<p>A textual representation of a \"missing value\" is sometimes used to clearly indicate that a blank or an empty value is to be interpreted as a missing piece of information. In datasets sourced from large databases, this \"missing value\" might consist of characters that do not adhere to a table or column schema. A simple example would be <code>###_MISSING_###</code> in place of a person's date of birth, since it does not conform to any common date format and consists entirely of letters and special characters.</p> <p>Gecko provides the function <code>with_missing_value</code> which replaces values within a series with a representative  \"missing value\". In the following example, 50% of all rows will be converted to a missing value.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(2905)\n\nmissing_mutator = mutator.with_missing_value(\"###_MISSING_###\", rng=rng)\nsrs = pd.Series([\"apple\", \"banana\", \"clementine\"])\nprint(missing_mutator([srs], 0.5))\n# =&gt; [[\"apple\", \"###_MISSING_###\", \"###_MISSING_###\"]]\n</code></pre>"},{"location":"data-mutation/#edit-errors","title":"Edit errors","text":"<p>Edit errors are caused by a set of operations on single characters within a word. There are commonly four operations that can induce these types of errors: insertion and deletion of a single character, substitution of a character with a different one, and transposition of two adjacent characters.</p> <p>Gecko provides mutators for each of these operations. For insertions and substitutions, it is possible to define a set of characters to choose from.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(8080)\nsrs = pd.Series([\"apple\", \"banana\", \"clementine\"])\n\ninsert_mutator = mutator.with_insert(charset=string.ascii_lowercase, rng=rng)\nprint(insert_mutator([srs], 1.0))\n# =&gt; [[\"appmle\", \"bananai\", \"clemenjtine\"]]\n\ndelete_mutator = mutator.with_delete(rng=rng)\nprint(delete_mutator([srs], 1.0))\n# =&gt; [[\"appl\", \"anana\", \"clemntine\"]]\n\nsubstitute_mutator = mutator.with_substitute(charset=string.ascii_lowercase, rng=rng)\nprint(substitute_mutator([srs], 1.0))\n# =&gt; [[\"apyle\", \"sanana\", \"clemeneine\"]]\n\ntranspose_mutator = mutator.with_transpose(rng=rng)\nprint(transpose_mutator([srs], 1.0))\n# =&gt; [[\"paple\", \"banaan\", \"cleemntine\"]]\n</code></pre>"},{"location":"data-mutation/#categorical-errors","title":"Categorical errors","text":"<p>Sometimes an attribute can only take on a set number of values. For example, if you have a \"gender\" column in your dataset, and it can only take on <code>m</code> for male, <code>f</code> for female and <code>o</code> for other, it wouldn't make sense for a mutated record to contain anything else except these three options.</p> <p>Gecko offers the <code>with_categorical_values</code> function for this purpose. It sources all possible options from a column in a CSV file and then applies random replacements respecting the limited available options.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(22)\nsrs = pd.Series([\"f\", \"m\", \"f\", \"f\", \"o\", \"m\", \"o\", \"o\"])\n\ncategorical_mutator = mutator.with_categorical_values(\n    \"./gender.csv\",  # CSV file containing \"gender\" column with \"f\", \"m\" and \"o\" as possible values\n    value_column=\"gender\",\n    rng=rng,\n)\n\nprint(categorical_mutator([srs], 1.0))\n# =&gt; [[\"m\", \"o\", \"m\", \"m\", \"m\", \"f\", \"m\", \"f\"]]\n</code></pre>"},{"location":"data-mutation/#value-permutations","title":"Value permutations","text":"<p>Certain types of information are easily confused with others. This is particularly true for names, where the differentiation between given and last names in a non-native language is challenging to get right. The <code>with_permute</code> function handles this exact use case. It simply swaps the values between series that are passed into it. In this example, 50% of all rows are permuted at random.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(1955104)\n\nsrs_given_name = pd.Series([\"Max\", \"Jane\", \"Jan\"])\nsrs_last_name = pd.Series([\"Mustermann\", \"Doe\", \"Jansen\"])\n\npermute_mutator = mutator.with_permute(rng=rng)\nprint(permute_mutator([srs_given_name, srs_last_name], 0.5))\n# =&gt; [[\"Max\", \"Doe\", \"Jan\"],\n#       [\"Mustermann\", \"Jane\", \"Jansen\"]]\n</code></pre>"},{"location":"data-mutation/#common-replacements","title":"Common replacements","text":"<p>Other various error sources, such as optical character recognition (OCR) errors, can be modeled using simple replacement tables. These tables have a source and a target column, defining mappings between character sequences.</p> <p>The <code>with_replacement_table</code> function achieves just that. Suppose you have the following CSV file with common OCR errors.</p> <pre><code>k,lc\n5,s\n2,z\n1,|\n</code></pre> <p>You can use this file the same way you can with many other generation and mutation functions in Gecko. Specifying the <code>inline</code> flag ensures that replacements are performed within words.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(6379)\nsrs = pd.Series([\"kick 0\", \"step 1\", \"go 2\", \"run 5\"])\n\nreplacement_mutator = mutator.with_replacement_table(\n    \"./ocr.csv\",\n    inline=True,\n    rng=rng,\n)\n\nprint(replacement_mutator([srs], 1.0))\n# =&gt; [\"lcick 0\", \"step |\", \"go z\", \"run s\"]\n</code></pre> <p>To only replace whole words, leave out the <code>inline</code> flag or set it to <code>False</code>. One use case is to replace names that sound or seem similar.</p> CSVTable <pre><code>source,target\nJan,Jann\nJan,Jean\nJan,John\nJan,Juan\nJann,Jean\nJann,Johann\nJann,John\nJann,Juan\n</code></pre> Source Target Jan Jann Jan Jean Jan John Jan Juan Jann Jean Jann Johann Jann John Jann Juan <p>Assuming the table shown above, one could perform randomized replacements using this mutator like so.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(6379)\nsrs = pd.Series([\"Jan\", \"Jann\", \"Juan\"])\n\nreplacement_mutator = mutator.with_replacement_table(\n    \"./given-names.csv\",\n    rng=rng,\n)\n\nprint(replacement_mutator([srs], 1.0))\n# =&gt; GeckoWarning: with_replacement_table: desired probability of 1.0 cannot be met since percentage of rows that could possibly be mutated is 0.6666666666666666\n# =&gt; [\"Jann\", \"Juan\", \"Juan\"]\n</code></pre> <p>Note how \"Juan\" is not replaced since it is only present in the \"target\" column, not the \"source\" column. By default, this mutator only considers replacement from the \"source\" to the \"target\" column. If it should also consider reverse replacements, set the <code>reverse</code> flag.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(6379)\nsrs = pd.Series([\"Jan\", \"Jann\", \"Juan\"])\n\nreplacement_mutator = mutator.with_replacement_table(\n    \"./given-names.csv\",\n    reverse=True,\n    rng=rng,\n)\n\nprint(replacement_mutator([srs], 1.0))\n# =&gt; [\"Jann\", \"Johann\", \"Jann\"]\n</code></pre>"},{"location":"data-mutation/#regex-replacements","title":"Regex replacements","text":"<p>Where the phonetic and generic replacement mutators do not fit the bill, replacements using regular expressions might come in handy. <code>with_regex_replacement_table</code> supports the application of mutations based on regular expressions. This mutator works off of CSV files which contain the regular expression patterns to look for and the substitutions  to perform as columns.</p> <p>Warning</p> <p>Before using this mutator, make sure that <code>with_phonetic_replacement_table</code> and <code>with_replacement_table</code> are not suitable for your use case.  These functions are more optimised, whereas <code>with_regex_replacement_table</code> has to perform  replacements on a mostly row-by-row basis which impacts performance.</p> <p>Let's assume that you want to perform mutations on a column containing dates where the digits of certain days should be flipped. A CSV file that is capable of these mutations could look as follows.</p> CSVTable <pre><code>pattern,1\n\"\\d{4}-\\d{2}-(30)\",\"03\"\n\"\\d{4}-\\d{2}-(20)\",\"02\"\n\"\\d{4}-\\d{2}-(10)\",\"01\"\n</code></pre> Pattern 1 <code>\\d{4}-\\d{2}-(30)</code> <code>03</code> <code>\\d{4}-\\d{2}-(20)</code> <code>02</code> <code>\\d{4}-\\d{2}-(10)</code> <code>01</code> <p>A mutator using the CSV file above would look for dates that have \"10\", \"20\" or \"30\" in their \"day\" field and flips the digits to \"01\", \"02\" and \"03\" respectively. This is done by placing a capture group around the \"day\" field in the regular expression. Since it is the first capture group, once a row matches, Gecko will look up the substitution in the column labelled \"1\" in the CSV file. This also works when using named capture groups, in which case Gecko will use the name of the capture group to look up  substitutions.</p> CSVTable <pre><code>pattern,day\n\"\\d{4}-\\d{2}-(?P&lt;day&gt;30)\",\"03\"\n\"\\d{4}-\\d{2}-(?P&lt;day&gt;20)\",\"02\"\n\"\\d{4}-\\d{2}-(?P&lt;day&gt;10)\",\"01\"\n</code></pre> Pattern Day <code>\\d{4}-\\d{2}-(?P&lt;day&gt;30)</code> <code>03</code> <code>\\d{4}-\\d{2}-(?P&lt;day&gt;20)</code> <code>02</code> <code>\\d{4}-\\d{2}-(?P&lt;day&gt;10)</code> <code>01</code> <p>Substitutions may also reference named capture groups. Suppose you want to flip the least significant digit of the \"day\" and \"month\" field under certain conditions. A CSV file capable of performing this type of substitution looks as follows.</p> CSVTable <pre><code>pattern,month,day\n\"\\d{4}-0(?P&lt;month&gt;[1-8])-[0-2](?P&lt;day&gt;[1-8])\",\"(?P&lt;day&gt;)\",\"(?P&lt;month&gt;)\"\n</code></pre> Pattern Month Day <code>\\d{4}-0(?P&lt;month&gt;[1-8])-[0-2](?P&lt;day&gt;[1-8])</code> <code>(?P&lt;day&gt;)</code> <code>(?P&lt;month&gt;)</code> <p><code>with_regex_replacement_table</code> works much like its \"phonetic\" and \"common\" siblings in that it requires a path to a CSV file as shown above and the name of the column containing the regex patterns to look for. The columns containing the substitution values are inferred at runtime. In the following snippet, the second example using named capture groups to flip the digits in the day field is shown.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(0x2321)\nsrs = pd.Series([\"2020-01-30\", \"2020-01-20\", \"2020-01-10\"])\n\nregex_mutator = mutator.with_regex_replacement_table(\n    \"./dob-day-digit-flip.csv\",\n    pattern_column=\"pattern\",\n    rng=rng\n)\n\nprint(regex_mutator([srs], 1.0))\n# =&gt; [\"2020-01-03\", \"2020-01-02\", \"2020-01-01\"]\n</code></pre> <p>It is also possible to define a column that contains regex flags. At the time, Gecko supports the <code>ASCII</code> and <code>IGNORECASE</code> flags which can be applied by adding <code>a</code> and <code>i</code> respectively  to the flag column.</p> CSVTable <pre><code>pattern,suffix,flags\n\"fooba(?P&lt;suffix&gt;r)\",\"z\",\"i\"\n</code></pre> Pattern Suffix Flags <code>fooba(?P&lt;suffix&gt;r)</code> <code>z</code> <code>i</code> <p>In the following snippet, case-insensitive matching will be performed. This causes all rows of the input series to be modified.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(0xCAFED00D)\nsrs = pd.Series([\"foobar\", \"Foobar\", \"fOoBaR\"])\n\nregex_mutator = mutator.with_regex_replacement_table(\n    \"./foobar.csv\",\n    pattern_column=\"pattern\",\n    flags_column=\"flags\",\n    rng=rng\n)\n\nprint(regex_mutator([srs], 1.0))\n# =&gt; [\"foobaz\", \"Foobaz\", \"fOoBaz\"]\n</code></pre>"},{"location":"data-mutation/#case-conversions","title":"Case conversions","text":"<p>During data entry or normalization, it may occur that text is converted to all lowercase or uppercase, by accident or on purpose. <code>with_lowercase</code> and <code>with_uppercase</code> handle these use cases. Gecko outputs warnings here because some values in the original series are already all lowercase and uppercase.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(9_0000_8479_1716)\nsrs = pd.Series([\"Foobar\", \"foobaz\", \"FOOBAT\"])\n\nlowercase_mutator = mutator.with_lowercase(rng=rng)\nuppercase_mutator = mutator.with_uppercase(rng=rng)\n\nprint(lowercase_mutator([srs], 1.0))\n# =&gt; GeckoWarning: with_lowercase: desired probability of 1.0 cannot be met since percentage of rows that could possibly be mutated is 0.6666666666666666\n# =&gt; [\"foobar\", \"foobaz\", \"foobat\"]\n\nprint(uppercase_mutator([srs], 1.0))\n# =&gt; GeckoWarning: with_uppercase: desired probability of 1.0 cannot be met since percentage of rows that could possibly be mutated is 0.6666666666666666\n# =&gt; [\"FOOBAR\", \"FOOBAZ\", \"FOOBAT\"]\n</code></pre>"},{"location":"data-mutation/#date-and-time-offsets","title":"Date and time offsets","text":"<p>Date and time information is prone to errors where single fields are offset by a couple units. This error source is implemented in the <code>with_datetime_offset</code> function. It requires a range in which time units can be offset by and the format of the data to mutate as expressed by Python's format codes for datetime objects. It is possible to apply offsets in units of days (<code>d</code>), hours (<code>h</code>), minutes (<code>m</code>) and seconds (<code>s</code>).</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nsrs = pd.Series(pd.date_range(\"2020-01-01\", \"2020-01-31\", freq=\"D\"))\nrng = np.random.default_rng(0xffd8)\n\ndatetime_mutator = mutator.with_datetime_offset(\n   max_delta=5, unit=\"d\", dt_format=\"%Y-%m-%d\", rng=rng\n)\n\nprint(datetime_mutator([srs], 1.0))\n# =&gt; [\"2019-12-30\", \"2019-12-29\", ..., \"2020-02-02\", \"2020-01-29\"]\n</code></pre> <p>When applying offsets, it might happen that the offset applied to a single field affects another field, e.g. subtracting a day from January 1st, 2020 will wrap around to December 31st, 2019. If this is not desired, Gecko offers an extra flag that prevents these types of wraparounds at the cost of leaving  affected rows untouched. Note how the first and last entry in the output of the snippet below remains unchanged when compared to the previous  snippet. Gecko outputs a warning to reflect this.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nsrs = pd.Series(pd.date_range(\"2020-01-01\", \"2020-01-31\", freq=\"D\"))\nrng = np.random.default_rng(0xffd8)\n\ndatetime_mutator = mutator.with_datetime_offset(\n   max_delta=5, unit=\"d\", dt_format=\"%Y-%m-%d\", prevent_wraparound=True, rng=rng\n)\n\nprint(datetime_mutator([srs], 1.0))\n# =&gt; GeckoWarning: with_datetime_offset: desired probability of 1.0 cannot be met since percentage of rows that could possibly be mutated is 0.9032258064516129\n# =&gt; [\"2020-01-01\", \"2020-01-02\", ..., \"2020-01-30\", \"2020-01-29\"]\n</code></pre>"},{"location":"data-mutation/#repeated-values","title":"Repeated values","text":"<p>Erroneous copy-paste operations may yield an unwanted duplication of values. This is implemented in Gecko's <code>with_repeat</code> mutator. By default, it appends values with a space, but a custom joining character can be defined as well.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(1_7117_4268)\nsrs = pd.Series([\"foo\", \"bar\", \"baz\"])\n\nrepeat_mutator = mutator.with_repeat(rng=rng)\nrepeat_mutator_no_space = mutator.with_repeat(join_with=\"\")\n\nprint(repeat_mutator([srs], 1.0))\n# =&gt; [\"foo foo\", \"bar bar\", \"baz baz\"]\n\nprint(repeat_mutator_no_space([srs], 1.0))\n# =&gt; [\"foofoo\", \"barbar\", \"bazbaz\"]\n</code></pre>"},{"location":"data-mutation/#using-generators","title":"Using generators","text":"<p><code>with_generator</code> can leverage Gecko's mutators to prepend, append or replace data. For instance, this can be used for emulating compound names for persons who have more than one given or last name. By default, this function adds a space when prepending or appending generated data, but this can be customized.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\ndef generate_foobar_suffix(rand: np.random.Generator):\n    def _generate(count: int) -&gt; list[pd.Series]:\n        return [pd.Series(rand.choice((\"bar\", \"baz\", \"bat\"), size=count))]\n\n    return _generate\n\nsrs = pd.Series([\"foo\"] * 100)\nrng = np.random.default_rng(0x25504446)\n\ngen_prepend_mutator = mutator.with_generator(generate_foobar_suffix(rng), \"prepend\")\nprint(gen_prepend_mutator([srs], 1.0))\n# =&gt; [\"bat foo\", \"bar foo\", ..., \"baz foo\", \"baz foo\"]\n\ngen_replace_mutator = mutator.with_generator(generate_foobar_suffix(rng), \"replace\")\nprint(gen_replace_mutator([srs], 1.0))\n# =&gt; [\"bar\", \"bar\", ..., \"baz\", \"bat\"]\n\ngen_append_mutator = mutator.with_generator(generate_foobar_suffix(rng), \"append\", join_with=\"\")\nprint(gen_append_mutator([srs], 1.0))\n# =&gt; [\"foobat\", \"foobat\", ..., \"foobat\", \"foobaz\"]\n\n# {} can be used as a placeholder for generated values\ngen_prepend_placeholder_mutator = mutator.with_generator(generate_foobar_suffix(rng), \"append\", join_with=\" ({})\")\nprint(gen_prepend_placeholder_mutator([srs], 1.0))\n# =&gt; [\"foo (bar)\", \"foo (baz)\", ..., \"foo (bat)\", \"foo (bar)\"]\n</code></pre>"},{"location":"data-mutation/#grouped-mutators","title":"Grouped mutators","text":"<p>When applying mutators that are mutually exclusive, <code>with_group</code> can be used. It can take a list of mutators or a list of weighted mutators as arguments. When providing a list of mutators, all mutators are applied with equal probability. When using weighted mutators, each mutator is applied with its assigned probability.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\nrng = np.random.default_rng(123)\nsrs = pd.Series([\"a\"] * 100)\n\nequal_prob_mutator = mutator.with_group([\n   mutator.with_insert(rng=rng),\n   mutator.with_delete(rng=rng),\n], rng=rng)\n\n(srs_mut_1,) = equal_prob_mutator([srs], 1.0)\nprint(srs_mut_1.str.len().value_counts())\n# =&gt; { 0: 44, 2: 56 }\n# no more single character values remain\n\nweighted_prob_mutator = mutator.with_group([\n   (.25, mutator.with_insert(rng=rng)),\n   (.25, mutator.with_delete(rng=rng)),\n], rng=rng)\n\n(srs_mut_2,) = weighted_prob_mutator([srs], 1.0)\nprint(srs_mut_2.str.len().value_counts())\n# =&gt; { 0: 25, 1: 51, 2: 24 }\n# half of the original single character values remain\n</code></pre>"},{"location":"data-mutation/#multiple-mutators","title":"Multiple mutators","text":"<p>Using <code>mutate_data_frame</code>, you can apply multiple mutators on many columns at once. It is possible to set probabilities for each mutator, as well as to define multiple mutators per column.</p> <pre><code>import string\n\nimport numpy as np\nimport pandas as pd\n\nfrom gecko import mutator\n\ndf = pd.DataFrame(\n    {\n        \"fruit\": [\"apple\", \"banana\", \"orange\"],\n        \"type\": [\"elstar\", \"cavendish\", \"mandarin\"],\n        \"weight_in_grams\": [\"241.0\", \"195.6\", \"71.1\"],\n        \"amount\": [\"3\", \"5\", \"6\"],\n        \"grade\": [\"B\", \"C\", \"B\"],\n    }\n)\n\nrng = np.random.default_rng(25565)\n\ndf_mutated = mutator.mutate_data_frame(df, [\n    ((\"fruit\", \"type\"), (.5, mutator.with_permute())),  # (1)!\n    (\"grade\", [  # (2)!\n        mutator.with_substitute(charset=string.ascii_uppercase, rng=rng),\n    ]),\n    (\"amount\", [  # (3)!\n        (.8, mutator.with_insert(charset=string.digits, rng=rng)),\n        (.2, mutator.with_delete(rng=rng))\n    ])\n])\n\nprint(df_mutated)\n# =&gt; [[\"fruit\", \"type\", \"weight_in_grams\", \"amount\", \"grade\"],\n#       [\"elstar\", \"apple\", \"241.0\", \"53\", \"M\"],\n#       [\"cavendish\", \"banana\", \"195.6\", \"59\", \"Q\"],\n#       [\"mandarin\", \"orange\", \"71.1\", \"68\", \"V\"]]\n</code></pre> <ol> <li>You can assign probabilities to a mutator for a column. In this case, the permutation mutator will be applied to    50% of all records. The remaining 50% remain untouched.</li> <li>You can assign multiple mutators to a column. In this case, all specified mutators will be applied to all rows.</li> <li>You can assign probabilities to multiple mutators for a column. In this case, the insertion and deletion mutator    are applied to 80% and 20% of all records respectively.</li> </ol>"},{"location":"release-notes/","title":"Release notes","text":""},{"location":"release-notes/#064-dec-6-2024","title":"0.6.4 (Dec 6, 2024)","text":""},{"location":"release-notes/#fixes","title":"Fixes","text":"<ul> <li>Fix <code>with_regex_replacement_table</code> mutator not behaving correctly when pattern only matches partly</li> </ul>"},{"location":"release-notes/#063-dec-4-2024","title":"0.6.3 (Dec 4, 2024)","text":""},{"location":"release-notes/#features","title":"Features","text":"<ul> <li>Improve randomized selection of replacements in mutators using replacement tables</li> </ul>"},{"location":"release-notes/#fixes_1","title":"Fixes","text":"<ul> <li>Fix phonetic replacement rules not being matched correctly against original data when the desired pattern occurs in multiple places</li> </ul>"},{"location":"release-notes/#062-nov-27-2024","title":"0.6.2 (Nov 27, 2024)","text":""},{"location":"release-notes/#features_1","title":"Features","text":"<ul> <li>Add placeholder option to <code>with_generator</code> for inserting generated values</li> </ul>"},{"location":"release-notes/#061-nov-15-2024","title":"0.6.1 (Nov 15, 2024)","text":""},{"location":"release-notes/#fixes_2","title":"Fixes","text":"<ul> <li>Fix indexing behavior in <code>dfbitlookup</code> when using NumPy data types</li> </ul>"},{"location":"release-notes/#060-nov-15-2024","title":"0.6.0 (Nov 15, 2024)","text":""},{"location":"release-notes/#breaking-changes","title":"Breaking changes","text":"<ul> <li>Change mutator type definition from <code>Callable[[list[pd.Series]], list[pd.Series]]</code> to <code>Callable[[list[pd.Series], Optional[float]], list[pd.Series]]</code> to delegate the selection of rows to mutate to the mutators themselves</li> <li><code>Generator</code> and <code>Mutator</code> type definitions are now exported at the top level of the module</li> <li>Replace <code>D</code> option in favor of <code>d</code> for <code>unit</code> parameter in <code>with_datetime_offset</code></li> <li>Remove <code>strategy</code> parameter from <code>with_missing_value</code></li> <li>Remove <code>rng</code> parameter from <code>mutate_data_frame</code></li> <li>Remove <code>with_edit</code> in favor of <code>with_group</code></li> </ul>"},{"location":"release-notes/#features_2","title":"Features","text":"<ul> <li><code>with_replacement_table</code>, <code>with_regex_replacement_table</code> and <code>with_phonetic_replacement_table</code> now favor rare replacements over common ones</li> <li>Add <code>rng</code> parameter to <code>with_function</code>, <code>with_lowercase</code>, <code>with_missing_value</code>, <code>with_noop</code>, <code>with_repeat</code>, <code>with_uppercase</code></li> <li><code>with_permute</code> now permutes series contents in a way that values are guaranteed to not remain in their original series</li> <li>Add <code>days</code>, <code>hours</code>, <code>minutes</code> and <code>seconds</code> to list of permitted <code>unit</code> values for <code>with_datetime_offset</code></li> <li>Add <code>list[str]</code> as option to <code>charset</code> parameter of <code>with_cldr_keymap_file</code>, <code>with_insert</code> and <code>with_substitute</code></li> </ul>"},{"location":"release-notes/#fixes_3","title":"Fixes","text":"<ul> <li>When providing a list of mutators to a column in <code>mutate_data_frame</code>, all mutators are now applied to all rows instead of with a <code>1 / mutator_count</code> probability</li> <li>Fix <code>with_regex_replacement_table</code> interpreting numbers in pattern and substitution columns as belonging to a named capture group </li> </ul>"},{"location":"release-notes/#documentation","title":"Documentation","text":"<ul> <li>Use section-style navigation instead of tabs in Gecko docs</li> </ul>"},{"location":"release-notes/#052-nov-5-2024","title":"0.5.2 (Nov 5, 2024)","text":""},{"location":"release-notes/#features_3","title":"Features","text":"<ul> <li>Add <code>generator.with_group</code> for grouping multiple (weighted) generators together</li> </ul>"},{"location":"release-notes/#internal","title":"Internal","text":"<ul> <li>Remove automated benchmarks</li> </ul>"},{"location":"release-notes/#051-oct-30-2024","title":"0.5.1 (Oct 30, 2024)","text":""},{"location":"release-notes/#features_4","title":"Features","text":"<ul> <li>Add the option to use data frames for all generators and mutators that accept paths to CSV files</li> </ul>"},{"location":"release-notes/#050-oct-23-2024","title":"0.5.0 (Oct 23, 2024)","text":""},{"location":"release-notes/#breaking-changes_1","title":"Breaking changes","text":"<ul> <li><code>to_data_frame</code> has a new call signature that ensures that it's consistent with <code>mutate_data_frame</code></li> </ul> <pre><code>df_generated = generator.to_data_frame(\n    [\n        ((\"fruit\", \"type\"), generator.from_multicolumn_frequency_table(\n            \"fruit-types.csv\",\n            value_columns=[\"fruit\", \"type\"],\n            freq_column=\"count\",\n            rng=rng,\n        )),\n        (\"weight\", generator.from_uniform_distribution(\n            low=20,\n            high=100,\n            rng=rng,\n        )),\n    ], \n    10_000\n)\n</code></pre>"},{"location":"release-notes/#features_5","title":"Features","text":"<ul> <li>Add <code>mutator.with_group</code> for grouping multiple mutators together</li> <li>Add support for Python 3.13</li> </ul>"},{"location":"release-notes/#documentation_1","title":"Documentation","text":"<ul> <li>Fix creation and modification timestamps in documentation</li> </ul>"},{"location":"release-notes/#042-sep-20-2024","title":"0.4.2 (Sep 20, 2024)","text":""},{"location":"release-notes/#fixes_4","title":"Fixes","text":"<ul> <li>Fix <code>NaN</code>s produced by generators and mutators that take in CSV files with empty cells</li> </ul>"},{"location":"release-notes/#041-sep-12-2024","title":"0.4.1 (Sep 12, 2024)","text":""},{"location":"release-notes/#features_6","title":"Features","text":"<ul> <li>Add <code>inline</code> and <code>reverse</code> flags to <code>with_replacement_table</code> mutator</li> </ul>"},{"location":"release-notes/#040-sep-10-2024","title":"0.4.0 (Sep 10, 2024)","text":""},{"location":"release-notes/#breaking-changes_2","title":"Breaking changes","text":"<ul> <li><code>mutate_data_frame</code> has a new call signature which ensures the order of mutation operations</li> </ul> <pre><code>df_mutated = mutator.mutate_data_frame(\n    df_original,\n    [\n        (\"gender\", (0.1, mutator.with_categorical_values(\n            \"./gender.csv\",\n            value_column=\"gender\",\n            rng=rng\n        ))),\n        ((\"given_name\", \"last_name\"), (0.05, mutator.with_permute())),\n        (\"postcode\", [\n            mutator.with_delete(rng=rng),\n            mutator.with_substitute(charset=\"0123456789\", rng=rng)\n        ])\n    ],\n    rng=rng\n)\n</code></pre>"},{"location":"release-notes/#features_7","title":"Features","text":"<ul> <li>Add <code>generator.from_datetime_range</code> for generating dates and times</li> <li>Add <code>mutator.with_lowercase</code> and <code>mutator.with_uppercase</code> for case conversions</li> <li>Add <code>mutator.with_datetime_offset</code> for applying arbitrary offsets to dates and times</li> <li>Add <code>mutator.with_generator</code> for appending, prepending or replacing data in a series with values from a generator</li> <li>Add <code>mutator.with_regex_replacement_table</code> for regex-based substitutions</li> <li>Add <code>mutator.with_repeat</code> for repeated values</li> </ul>"},{"location":"release-notes/#fixes_5","title":"Fixes","text":"<ul> <li>Fix <code>mutate_data_frame</code> raising an error if probability is provided as an integer, not a float</li> </ul>"},{"location":"release-notes/#032-jul-19-2024","title":"0.3.2 (Jul 19, 2024)","text":""},{"location":"release-notes/#fixes_6","title":"Fixes","text":"<ul> <li>Fix multiple mutators not being applied correctly when defined on the same column</li> </ul>"},{"location":"release-notes/#031-mar-28-2024","title":"0.3.1 (Mar 28, 2024)","text":""},{"location":"release-notes/#fixes_7","title":"Fixes","text":"<ul> <li>Fix <code>IndexError</code> when calling <code>with_permute</code> on empty series</li> <li>Fix Python version range in <code>pyproject.toml</code></li> </ul>"},{"location":"release-notes/#refactors","title":"Refactors","text":"<ul> <li>Fix type hint on <code>**kwargs</code> in benchmarks</li> </ul>"},{"location":"release-notes/#documentation_2","title":"Documentation","text":"<ul> <li>Add navigation tabs to documentation</li> <li>Fix image link in README so that it can be displayed on PyPI</li> </ul>"},{"location":"release-notes/#internal_1","title":"Internal","text":"<ul> <li>Cache dependencies in CI pipelines</li> <li>Reorganize dependencies into groups for tests, development and documentation</li> </ul>"},{"location":"release-notes/#030-mar-18-2024","title":"0.3.0 (Mar 18, 2024)","text":""},{"location":"release-notes/#features_8","title":"Features","text":"<ul> <li>Allow <code>corruptor.with_permute</code> to work with more than two series at once</li> <li>Infer <code>header</code> parameter for functions reading CSV files</li> <li>Remove list length constraints from <code>mutator</code> module</li> </ul>"},{"location":"release-notes/#refactors_1","title":"Refactors","text":"<ul> <li>Fix type hints on <code>*args</code> and <code>**kwargs</code></li> <li>Rename <code>corruptor</code> module to <code>mutator</code></li> <li>Rename <code>Corruptor</code> type alias to <code>Mutator</code></li> <li>Rename <code>corruptor.corrupt_dataframe</code> to <code>mutator.mutate_data_frame</code></li> <li>Rename <code>generator.to_dataframe</code> to <code>generator.to_dataframe</code></li> </ul>"},{"location":"release-notes/#documentation_3","title":"Documentation","text":"<ul> <li>Add API reference to documentation</li> <li>Update docs to use new \"mutator\" terminology wherever possible</li> <li>Use Google format docstrings instead of reST</li> </ul>"},{"location":"release-notes/#internal_2","title":"Internal","text":"<ul> <li>Merge documentation repository into main repository</li> <li>Move repositories from GitLab to GitHub</li> <li>Refine benchmark suite, add example based on German population dataset</li> </ul>"},{"location":"release-notes/#020-feb-16-2024","title":"0.2.0 (Feb 16, 2024)","text":""},{"location":"release-notes/#features_9","title":"Features","text":"<ul> <li>Add <code>generator.with_permute</code> for swapping values between series</li> <li>Set wider version ranges for dependencies</li> <li>Fix <code>corruptor.corrupt_dataframe</code> to not modify original data frame</li> <li>Add tests to all corruptor functions to ensure no modifications to original data</li> </ul>"},{"location":"release-notes/#refactors_2","title":"Refactors","text":"<ul> <li>Change generators to take in and return a list of series instead of single series</li> <li>Change <code>generator.to_dataframe</code> signature to align with <code>corruptor.corrupt_dataframe</code></li> </ul>"},{"location":"release-notes/#internal_3","title":"Internal","text":"<ul> <li>Extend CI pipeline with a benchmarking step that runs on release and when manually triggered</li> <li>Add benchmark based on the \"fruits\" example in the docs</li> </ul>"},{"location":"release-notes/#010-feb-8-2024","title":"0.1.0 (Feb 8, 2024)","text":"<ul> <li>Initial release</li> </ul>"},{"location":"examples/german/","title":"Example: German population dataset","text":"<p>In this example, you will create a script that generates and mutates a dataset of German persons. To get started, create a new directory for your project. Within it, create an empty <code>main.py</code> file. Install Gecko and obtain a copy of the Gecko data repository. If you have Git installed, you can simply clone it into your project directory with the following command.</p> <pre><code>git clone https://github.com/ul-mds/gecko-data.git\n</code></pre> <p>Your project directory should look something like this:</p> <pre><code>|- gecko-data/\n|- main.py\n|- poetry.lock       (only if you use Poetry)\n|- pyproject.toml    (only if you use Poetry)\n</code></pre> <p>The Gecko data repository contains mostly CSV files which have been generated from publicly available datasets. It is a decent starting point if you just want to explore Gecko's capabilities.</p>"},{"location":"examples/german/#setting-up-the-script","title":"Setting up the script","text":"<p>To get started, edit your <code>main.py</code> and import Numpy, Pandas and Gecko's generator and mutator module. Numpy is needed to create a random number generator (RNG) with a fixed starting point so that the generated data remains consistent across script executions. Most modern code editors should be able to make use of that.</p> <pre><code>import numpy as np  # (1)!\n\nfrom gecko import generator, mutator\n\nif __name__ == \"__main__\":  # (2)!\n    rng = np.random.default_rng(727)  # (3)!\n</code></pre> <ol> <li>Numpy is imported to make use of its random number generator (RNG). Numpy's RNG functions are extensively used in    Gecko's built-in generators and mutators.</li> <li>This is standard Python boilerplate code. All code in this block is executed when the script is explicitly run    using <code>python main.py</code>.</li> <li>This line creates a new RNG with a fixed starting point. You can choose any number you want here. Go crazy!</li> </ol> <p>Tip: Click on the  icon in the code snippets to get extra info on what a line of code does.</p> <p>Next, add two functions to your script. <code>generate_data_frame</code> takes in a number of records to generate and a RNG. For now this function is empty, but when it's complete, it will return a data frame with the desired amount of rows. <code>mutate_data_frame</code> takes in a data frame and a RNG and returns a modified copy of the data frame that is passed into it.</p> <p>Add two lines to your main code block to call the functions that you just created. Set the amount of records to any number you want. In this example, the aim is to generate 100k records.</p> <pre><code>import numpy as np\n\nfrom gecko import generator, mutator\n\n\ndef generate_data_frame(count, rng):  # (1)!\n    pass\n\n\ndef mutate_data_frame(df, rng):  # (2)!\n    pass\n\n\nif __name__ == \"__main__\":\n    rng = np.random.default_rng(727)\n    df_original = generate_data_frame(100_000, rng)  # (3)!\n    df_mutated = mutate_data_frame(df_original, rng)\n</code></pre> <ol> <li>Once complete, this function will generate a data frame with generated data. The amount of rows is set with    the <code>count</code> parameter. Data frames are, in essence, Pandas' representation of two-dimensional tabular data.</li> <li>Once complete, this function will mutate the data frame that is passed into it and return the mutated copy. <code>df</code>    is a common shorthand for \"data frame\".</li> <li>Gecko works with Pandas data types. If you are familiar with Pandas, you will find working with the results generated    by Gecko to be easy. A few use cases will be demonstrated later in this example.</li> </ol>"},{"location":"examples/german/#generating-data","title":"Generating data","text":"<p>Now it's finally time to generate some data. The Gecko data repository contains a CSV file for the most common last names found in Germany. It consists of two columns: <code>last_name</code> and <code>count</code>. To use it with Gecko, use the <code>from_frequency_table</code> function from the <code>generator</code> module.</p> <pre><code>from gecko import generator\n\n\ndef generate_data_frame(count, rng):  # (1)!\n    gen_last_name = generator.from_frequency_table(\n        \"gecko-data/de_DE/last-name.csv\",  # (2)!\n        value_column=\"last_name\",  # (3)!\n        freq_column=\"count\",  # (4)!\n        rng=rng,  # (5)!\n    )\n</code></pre> <ol> <li>For brevity, the rest of the script is excluded from this snippet. Bear in mind that all code you write belongs in    your <code>main.py</code> file.</li> <li>This is the path to the CSV file. It's relative to the location of the <code>main.py</code> file.</li> <li>This is the name of the column in the CSV file that contains the values to generate.</li> <li>This is the name of the column in the CSV file that contains the absolute frequency per value.</li> <li>Almost every function in Gecko allows for a RNG to be passed in. Reusing the same RNG in your script is crucial to    ensure reproducibility. If no RNG is passed in, Gecko will use a new RNG with a random starting point.</li> </ol> <p>Last names aren't everything though. Next to last names, the Gecko data repository provides a CSV file with given names, as well as a gender code to state whether a given name is more predominantly assigned to males or females.</p> <p>This highlights an important aspect about generating realistic data. Even though data in the real world might seem random, it rarely is. Names depend on gender at birth, ethnicity, trends in baby names over time and many other social factors. Gecko provides the tools to generate data according to these complex dependencies. Since this is an entry-level example, we will keep it as simple as possible. But if you start to curate your own data sources for use with Gecko, keep in mind that more variables make for a more realistic dataset.</p> <p>To generate data from CSV files with multiple interdependent columns, use Gecko's <code>from_multicolumn_frequency_table</code> function. Its syntax is almost the same as <code>from_frequency_table</code>, except it allows for multiple value columns to be specified.</p> <pre><code>from gecko import generator\n\n\ndef generate_data_frame(count, rng):\n    gen_last_name = generator.from_frequency_table(\n        \"gecko-data/de_DE/last-name.csv\",\n        value_column=\"last_name\",\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_given_name_gender = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/given-name-gender.csv\",\n        value_columns=[\"given_name\", \"gender\"],  # (1)!\n        freq_column=\"count\",\n        rng=rng,\n    )\n</code></pre> <ol> <li>Note how this function accepts multiple column names. The generator will use this information to generate multiple    columns at once.</li> </ol> <p>Gecko can provide generators that create one or two columns at a time, but can it do more than that? Of course. There are technically no limits to the amount of interdependent data it can generate ... except the computational and memory constraints of your machine. So let's add one more complex generator.</p> <p>The Gecko data repository has a CSV file with a non-exhaustive list of street names in Germany. As stated previously, street names are not random just like every other piece of personal information, so the file also lists the municipalities and post codes where each street can be found. Again, use <code>from_multicolumn_frequency_table</code> and pass in the corresponding column names to generate data from.</p> <pre><code>from gecko import generator\n\n\ndef generate_data_frame(count, rng):\n    gen_last_name = generator.from_frequency_table(\n        \"gecko-data/de_DE/last-name.csv\",\n        value_column=\"last_name\",\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_given_name_gender = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/given-name-gender.csv\",\n        value_columns=[\"given_name\", \"gender\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_street_municip_postcode = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/street-municipality-postcode.csv\",\n        value_columns=[\"street_name\", \"municipality\", \"postcode\"],  # (1)!\n        freq_column=\"count\",\n        rng=rng,\n    )\n</code></pre> <ol> <li>Gecko can work with any amount of value columns, as long as your machine allows for the generation of all that data,    of course.</li> </ol> <p>To tie it all together, Gecko offers the <code>to_data_frame</code> function. Pass it a list of generators and the column names for each generator and Gecko will generate a data frame according to your specification.</p> <pre><code>from gecko import generator\n\n\ndef generate_data_frame(count, rng):\n    gen_last_name = generator.from_frequency_table(\n        \"gecko-data/de_DE/last-name.csv\",\n        value_column=\"last_name\",\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_given_name_gender = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/given-name-gender.csv\",\n        value_columns=[\"given_name\", \"gender\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_street_municip_postcode = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/street-municipality-postcode.csv\",\n        value_columns=[\"street_name\", \"municipality\", \"postcode\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    return generator.to_data_frame([  # (1)!\n        ((\"given_name\", \"gender\"), gen_given_name_gender),  # (2)!\n        (\"last_name\", gen_last_name),  # (3)!\n        ((\"street_name\", \"municipality\", \"postcode\"), gen_street_municip_postcode),\n    ], count)\n</code></pre> <ol> <li>The <code>to_data_frame</code> function takes two arguments: a list of generators and column names, and the number of records to    generate.</li> <li>You must provide one or multiple column names for each generator, depending on how many columns a generator creates.</li> <li>If a generator returns only a single column, you can provide a single string. Otherwise, you must provide a tuple of    strings.</li> </ol>"},{"location":"examples/german/#mutating-data","title":"Mutating data","text":"<p>Now that we have a data frame with lots of generated data, we can mutate it. Gecko's <code>mutator</code> module exposes the <code>mutate_data_frame</code> function which allows you to apply any number of mutators on the columns of a data frame.</p> <p>A common source of errors in a dataset are optical character recognition (OCR) errors. This happens when a physical document is scanned into an image and an OCR software attempts to extract its textual contents. The Gecko data repository contains a file with common OCR errors which, in fact, has been sourced straight from the original GeCo framework which inspired Gecko.</p> <p>To perform random inline replacements of letters within a word, use the <code>with_replacement_table</code> function from the <code>mutator</code> module. You might notice that this function does not require extra configuration to read the CSV file with the OCR replacements. If left unconfigured, Gecko will select the first and second column in this case. This is exactly what we want, so we can leave all other parameters unset. For this example, apply the mutator to 10% of all values in the <code>given_name</code> column.</p> <pre><code>from gecko import mutator\n\n\ndef mutate_data_frame(df, rng):\n    return mutator.mutate_data_frame(df, [  # (1)!\n        (\"given_name\", [\n            (0.1, mutator.with_replacement_table(  # (2)!\n                \"gecko-data/common/ocr.csv\",\n                inline=True,\n                rng=rng,\n            ))\n        ])\n    ]) \n</code></pre> <ol> <li>The <code>mutate_data_frame</code> function takes in two arguments: the data frame to mutate and a list. This list    maps column names to a list of mutators to apply to this column.</li> <li>Each column is assigned a list. This list contains entries that define how mutators should be applied. The syntax    for each entry is <code>(probability, mutator)</code>. So in this case, the replacement table mutator is applied to 10% of    all values in the <code>given_name</code> column. The remaining 90% remain untouched.</li> </ol> <p>For columns such as <code>gender</code>, the available options are limited. In this example, it can only take on the values <code>m</code> and <code>f</code>. Replacing it with anything else wouldn't make a lot of sense.</p> <p>Columns with a limited set of permitted values can be mutated using the <code>with_categorical_values</code> function. This ensures that values within this column are only replaced with another valid value. You can reuse the CSV file containing given names and gender codes for this purpose. Point the mutator to the <code>gender</code> column, and it'll automatically pick out all unique values within it. For this example, the mutator should modify 2% of all rows.</p> <pre><code>from gecko import mutator\n\n\ndef mutate_data_frame(df, rng):\n    return mutator.mutate_data_frame(df, [\n        (\"given_name\", [\n            (0.1, mutator.with_replacement_table(\n                \"gecko-data/common/ocr.csv\",\n                inline=True,\n                rng=rng,\n            ))\n        ]),\n        (\"gender\", [\n            (0.02, mutator.with_categorical_values(  # (1)!\n                \"gecko-data/de_DE/given-name-gender.csv\",\n                value_column=\"gender\",\n                rng=rng,\n            ))\n        ])\n    ])\n</code></pre> <ol> <li>The <code>with_categorical_values</code> function allows you to reuse the same files that you used to generate your data. The    function call is similar to the frequency table functions in the <code>generator</code> module.</li> </ol> <p>So far all you've done is apply a single mutator to a column, but Gecko allows you to apply as many mutators as you want to a column. Let's suppose that a few entries in the <code>gender</code> column are supposed to be missing. The <code>with_missing_value</code> function handles this exact use case. It replaces values with a representative \"missing value\", which is an empty string by default. Extend the list of mutators for the <code>gender</code> column by applying the missing value mutator to 5% of all records.</p> <pre><code>from gecko import mutator\n\n\ndef mutate_data_frame(df, rng):\n    return mutator.mutate_data_frame(df, [\n        (\"given_name\", [\n            (0.1, mutator.with_replacement_table(\n                \"gecko-data/common/ocr.csv\",\n                inline=True,\n                rng=rng,\n            ))\n        ]),\n        (\"gender\", [\n            (0.02, mutator.with_categorical_values(\n                \"gecko-data/de_DE/given-name-gender.csv\",\n                value_column=\"gender\",\n                rng=rng,\n            )),\n            (0.05, mutator.with_missing_value(\n                value=\"\",  # (1)!\n                rng=rng\n            ))\n        ])\n    ])\n</code></pre> <ol> <li>By default, this mutator uses an empty string as the \"missing value\". You don't need to add this parameter if you    are happy with empty strings, but it's good practice nonetheless to be as explicit as possible in case the default    value changes in the future.</li> </ol> <p>Another common source of errors are typos on a keyboard. Gecko can read keymaps from the Unicode Common Locale Data Repository (CLDR) and apply typos based on them. Download the German CLDR keymap and place it next to your <code>main.py</code> script.</p> <p>We'll focus on the <code>postcode</code> column this time and assume that someone might slip with their finger during data entry and enter a wrong digit from time to time. The number row on the German keyboard is surrounded by many keys that don't generate digits. The <code>with_cldr_keymap_file</code> function accounts for that, granted that you pass it a string of allowed characters.</p> <pre><code>from gecko import mutator\n\n\ndef mutate_data_frame(df, rng):\n    return mutator.mutate_data_frame(df, [\n        (\"given_name\", [\n            (0.1, mutator.with_replacement_table(\n                \"gecko-data/common/ocr.csv\",\n                inline=True,\n                rng=rng,\n            ))\n        ]),\n        (\"gender\", [\n            (0.02, mutator.with_categorical_values(\n                \"gecko-data/de_DE/given-name-gender.csv\",\n                value_column=\"gender\",\n                rng=rng,\n            )),\n            (0.05, mutator.with_missing_value(\n                value=\"\",\n                rng=rng,\n            ))\n        ]),\n        (\"postcode\", [\n            (0.01, mutator.with_cldr_keymap_file(\n                \"de-t-k0-windows.xml\",  # (1)!\n                charset=\"0123456789\",  # (2)!\n                rng=rng,\n            ))\n        ])\n    ])\n</code></pre> <ol> <li>The <code>with_cldr_keymap_file</code> function can read any CLDR    keymap. Beware of limitations however since CLDR keymaps are currently    undergoing a large revision.</li> <li>By constraining the mutator this way, digits on the German keyboard can only be replaced with neighboring digits.</li> </ol>"},{"location":"examples/german/#putting-it-all-together","title":"Putting it all together","text":"<p>It's done! Well, for now at least.</p> <p>Gecko provides many more functions for generating and mutating realistic data. This example is a primer to show you the ropes. Feel free to extend this basic example with your own generators and mutators.</p> <p>To wrap things up, export the original and mutated data frames into their own CSV files. You can use Pandas' <code>to_csv</code> function to accomplish this. Your final script should look something like this.</p> <pre><code>import numpy as np\n\nfrom gecko import generator, mutator\n\n\ndef generate_data_frame(count, rng):\n    gen_last_name = generator.from_frequency_table(\n        \"gecko-data/de_DE/last-name.csv\",\n        value_column=\"last_name\",\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_given_name_gender = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/given-name-gender.csv\",\n        value_columns=[\"given_name\", \"gender\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_street_municip_postcode = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/street-municipality-postcode.csv\",\n        value_columns=[\"street_name\", \"municipality\", \"postcode\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    return generator.to_data_frame([\n        ((\"given_name\", \"gender\"), gen_given_name_gender),\n        (\"last_name\", gen_last_name),\n        ((\"street_name\", \"municipality\", \"postcode\"), gen_street_municip_postcode),\n    ], count)\n\n\ndef mutate_data_frame(df, rng):\n    return mutator.mutate_data_frame(df, [\n        (\"given_name\", [\n            (0.1, mutator.with_replacement_table(\n                \"gecko-data/common/ocr.csv\",\n                inline=True,\n                rng=rng,\n            ))\n        ]),\n        (\"gender\", [\n            (0.02, mutator.with_categorical_values(\n                \"gecko-data/de_DE/given-name-gender.csv\",\n                value_column=\"gender\",\n                rng=rng,\n            )),\n            (0.05, mutator.with_missing_value(\n                value=\"\",\n                rng=rng,\n            ))\n        ]),\n        (\"postcode\", [\n            (0.01, mutator.with_cldr_keymap_file(\n                \"de-t-k0-windows.xml\",\n                charset=\"0123456789\",\n                rng=rng,\n            ))\n        ])\n    ])\n\n\nif __name__ == \"__main__\":\n    rng = np.random.default_rng(727)\n    df_original = generate_data_frame(100_000, rng)\n    df_mutated = mutate_data_frame(df_original, rng)\n    df_original.to_csv(\"german-original.csv\", index_label=\"id\")  # (1)!\n    df_mutated.to_csv(\"german-mutated.csv\", index_label=\"id\")\n</code></pre> <ol> <li>This highlights one of the main reasons why Gecko works on Pandas data types. It facilitates the inclusion into    regular data science applications. You can use all your knowledge of Pandas on the results that Gecko provides to    you.</li> </ol> <p>All that's left to do is to run <code>python main.py</code> and examine the fruits of your labor.</p>"},{"location":"examples/german/#bonus-writing-your-own-generator","title":"Bonus: Writing your own generator","text":"<p>Gecko comes with a lot of built-in functions, but you are free to write your own generators. Remember: a generator is a function that takes in a number of records and returns a list of Pandas series. As long as your custom function abides by this, Gecko is happy to work with it.</p> <p>Suppose you want to generate a random date of birth for every person in your synthetic dataset. Add a new function to your script called <code>create_date_of_birth_generator</code>.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import Generator\nfrom typing import Optional\n\n\ndef create_date_of_birth_generator(\n        start_date: str = \"1920-01-01\",  # (1)!\n        end_date: str = \"2000-01-01\",\n        rng: Optional[np.random.Generator] = None,  # (2)!\n) -&gt; Generator:\n    pass\n</code></pre> <ol> <li>If no start or end date is specified, the function will use January 1st, 1920 and January 1st, 2000 as the default    boundaries.</li> <li>Almost all built-in functions in Gecko allow a custom RNG to be passed in. If no RNG is specified, a new RNG is used.    It's a good idea to stick to this convention in your own generators.</li> </ol> <p>Some more boilerplate code is required. First, if <code>rng</code> is <code>None</code>, then the function should use a new RNG with a random starting point. Second, your function needs to return a generator, so create a nested function that follows the requirements for it to be recognized as a generator.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import Generator\nfrom typing import Optional\n\n\ndef create_date_of_birth_generator(\n        start_date: str = \"1920-01-01\",\n        end_date: str = \"2000-01-01\",\n        rng: Optional[np.random.Generator] = None,\n) -&gt; Generator:\n    if rng is None:  # (1)!\n        rng = np.random.default_rng()\n\n    def _generate(count: int) -&gt; list[pd.Series]:  # (2)!\n        return []\n\n    return _generate  # (3)!\n</code></pre> <ol> <li>If no RNG is supplied to this function, then it will use a new RNG with a random starting    point. See the Numpy docs on    <code>default_rng</code> for more information.</li> <li>This is the actual generator function that will take care of generating random data. It must take in a number and    return a list of series.</li> <li>The generator is returned by your function. This means whenever you call <code>create_date_of_birth_generator</code> in your    code, you will actually receive the nested <code>_generate</code> function.</li> </ol> <p>The way we're going to generate random dates in this example is to take the start date and add a random amount of days to it. Numpy offers functions that simplify working with dates and times.</p> <p>First, you need to parse the start and end dates into Numpy's <code>datetime64</code> objects. To get the amount of days between the start and end date, subtract the start date from the end date to obtain a <code>timedelta64</code>.</p> <p>Converting <code>timedelta64</code> into a number of days isn't as trivial though. To make this work, divide it by a time delta of one day. This returns a floating point number, which you can then convert into an integer.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import Generator\nfrom typing import Optional\n\n\ndef create_date_of_birth_generator(\n        start_date: str = \"1920-01-01\",\n        end_date: str = \"2000-01-01\",\n        rng: Optional[np.random.Generator] = None,\n) -&gt; Generator:\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        start_dt = np.datetime64(start_date)  # (1)!\n        end_dt = np.datetime64(end_date)\n        delta = end_dt - start_dt  # (2)!\n        days_delta = int(delta / np.timedelta64(1, \"D\"))  # (3)!\n\n        return []\n\n    return _generate\n</code></pre> <ol> <li>Parsing dates in Numpy is as simple as wrapping it into <code>np.datetime64</code>, given that the date is provided in ISO 8601    format.</li> <li>Subtracting <code>np.datetime64</code> from one another yields a <code>np.timedelta64</code>.</li> <li>By diving the time delta by one day, this line will return the amount of days in the time delta as a floating point    number. It is then converted into an integer.</li> </ol> <p>Now you can generate random days to add to the start date. Use Numpy's RNG <code>integers</code> function to quickly generate many numbers at once. By setting <code>endpoint</code> to <code>True</code>, you're ensuring that the upper bound is included in the random number generation.</p> <p>Armed with a random list of numbers, you can add them to the start date and receive a list of random dates ranging from the specified start to the end date. Since the list will contain instances of <code>datetime64</code>, they will need to be converted into strings. <code>np.char.mod</code> takes care of that.</p> <p>Beware that a generator must return a list of series, so even if you're returning a single series, you must wrap it into a list.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import Generator\nfrom typing import Optional\n\n\ndef create_date_of_birth_generator(\n        start_date: str = \"1920-01-01\",\n        end_date: str = \"2000-01-01\",\n        rng: Optional[np.random.Generator] = None,\n) -&gt; Generator:\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        start_dt = np.datetime64(start_date)\n        end_dt = np.datetime64(end_date)\n        delta = end_dt - start_dt\n        days_delta = int(delta / np.timedelta64(1, \"D\"))\n\n        random_days = rng.integers(low=0, high=days_delta, size=count, endpoint=True)  # (1)!\n        random_dates = start_dt + random_days  # (2)!\n        random_date_strs = np.char.mod(\"%s\", random_dates)  # (3)!\n\n        return [pd.Series(random_date_strs)]  # (4)!\n\n    return _generate\n</code></pre> <ol> <li>Numpy's RNG functions are optimized to generate many numbers at once. Gecko uses these functions wherever possible.    In your code, you should try to use these functions as well as to not affect performance when generating millions of    records.</li> <li>By adding the list of random days to the starting date, we get a list of random dates.</li> <li>The list of random dates consists of <code>datetime64</code> instances, so they need to be converted to strings before being    returned.</li> <li>Generators must always return a list of series, so even a single series must be wrapped into a list.</li> </ol> <p>And there you go! Now you have your own generator that you can plug into Gecko with no issues. Expand the <code>generate_data_frame</code> function by adding your own generator.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom gecko import Generator\nfrom typing import Optional\n\nfrom gecko import generator\n\n\ndef create_date_of_birth_generator(\n        start_date: str = \"1920-01-01\",\n        end_date: str = \"2000-01-01\",\n        rng: Optional[np.random.Generator] = None,\n) -&gt; Generator:\n    if rng is None:\n        rng = np.random.default_rng()\n\n    def _generate(count: int) -&gt; list[pd.Series]:\n        start_dt = np.datetime64(start_date)\n        end_dt = np.datetime64(end_date)\n        delta = end_dt - start_dt\n        days_delta = int(delta / np.timedelta64(1, \"D\"))\n\n        random_days = rng.integers(low=0, high=days_delta, size=count, endpoint=True) \n        random_dates = start_dt + random_days \n        random_date_strs = np.char.mod(\"%s\", random_dates) \n\n        return [pd.Series(random_date_strs)] \n\n    return _generate\n\n\ndef generate_data_frame(count, rng):\n    gen_last_name = generator.from_frequency_table(\n        \"gecko-data/de_DE/last-name.csv\",\n        value_column=\"last_name\",\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_given_name_gender = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/given-name-gender.csv\",\n        value_columns=[\"given_name\", \"gender\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_street_municip_postcode = generator.from_multicolumn_frequency_table(\n        \"gecko-data/de_DE/street-municipality-postcode.csv\",\n        value_columns=[\"street_name\", \"municipality\", \"postcode\"],\n        freq_column=\"count\",\n        rng=rng,\n    )\n\n    gen_date_of_birth = create_date_of_birth_generator(rng=rng)  # (1)!\n\n    return generator.to_data_frame([\n        ((\"given_name\", \"gender\"), gen_given_name_gender),\n        (\"last_name\", gen_last_name),\n        ((\"street_name\", \"municipality\", \"postcode\"), gen_street_municip_postcode),\n        (\"date_of_birth\", gen_date_of_birth)  # (2)!\n    ], count)\n</code></pre> <ol> <li>Now you have a reusable generator with a configurable start and end date. As long as a function returns a generator,    it can be seamlessly used with Gecko.</li> <li>As with all other generators, your custom generator is accepted by <code>to_data_frame</code> by simply assigning it a column    name.</li> </ol>"}]}